{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4508,"status":"ok","timestamp":1700298664157,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"ZdukimZf3x4K","outputId":"21460b2d-7160-41f2-b947-c60778ff1b45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[Errno 2] No such file or directory: 'drive/My Drive/Thesis/CPNN_PiggyBack'\n","/content/drive/My Drive/Thesis/CPNN_PiggyBack\n","CSS   datasets\tmodels\t     push_to_git.ipynb\trequirements.txt  run_test\n","data  lab\tperformance  README.md\t\tresults\t\t  Untitled0.ipynb\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# going to the repository of this note book\n","%cd drive/My Drive/Thesis/CPNN_PiggyBack\n","!ls"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700298667427,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"I7eBx3S83u4k"},"outputs":[],"source":["# IMPORT\n","import os\n","from models.cpnn import *\n","from models.cpnn_others import cPNNExp\n","from models.cpnn_seq import cPNNSeq\n","from models.cgru import cGRULinear\n","from models.clstm import *\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import argparse"]},{"cell_type":"markdown","metadata":{"id":"GX5Ags7UP5I2"},"source":["##This part is related to run CPNN with gru layers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2496813,"status":"ok","timestamp":1699567258900,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"kmx2jJvj3nv1","outputId":"e193f28f-b31b-4f09-a6d7-543ae7363ea9"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'models.cgru.cGRULinear'>\n","sine_rw10_mode5_extended_16-16_1234\n","cGRULinear\n","1/1 iteration of cpnn\n","TASK: 1\n","\n","Accuracy media sul task 1: 0.9086437020460358\n","\n","TASK: 2\n","\n","Accuracy media sul task 2: 0.837380115089514\n","\n","TASK: 3\n","\n","Accuracy media sul task 3: 0.9426550511508951\n","\n","TASK: 4\n","\n","Accuracy media sul task 4: 0.8814737851662404\n","\n","\n"]}],"source":["\n","# EDITABLE PARAMETERS\n","dataset = \"sine_rw10_mode5_extended_16-16_1234\"\n","\n","# OTHER PARAMETERS\n","batch_size = 128\n","hidden_size = 250\n","seq_len = 10\n","# TODO\n","iterations = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","rembember_initial_states = False\n","suffix = \"\"\n","\n","if freeze_inputs_weights:\n","    suffix += \"_exp\"\n","if combination:\n","    suffix = \"_combination\" + suffix\n","if suffix != \"\" and suffix[0:1] != \"_\":\n","    suffix = \"_\" + suffix\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\n","    \"--model\",\n","    type=str,\n","    default=\"cpnn\",\n","    help=\"Model to use: {'cpnn', 'single': cLSTM, 'multiple': mcLSTM}\",\n",")\n","parser.add_argument(\n","    \"--model_class\",\n","    type=str,\n","    default=\"cgru\",\n","    help=\"Base learner to use: {'clstm', 'cgru'}\",\n",")\n","args,_ = parser.parse_known_args()\n","\n","if args.model_class == \"clstm\":\n","    model_class = cLSTMLinear\n","else:\n","    model_class = cGRULinear\n","if hidden_size is None:\n","    if args.model_class == \"clstm\":\n","        hidden_size = 50\n","    else:\n","        hidden_size = 128\n","device = torch.device(\"cpu\")\n","df = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}.csv\"))\n","perf_test = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_train = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_anytime = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": []}\n","seq_str = \"_seq\" if loss_on_seq else \"\"\n","\n","path = os.path.join(\n","    \"performance\",\n","    f\"{dataset}/{args.model}_{args.model_class}{seq_str}{suffix}_{hidden_size}hs\",\n",")\n","if not os.path.isdir(path):\n","    os.makedirs(path)\n","\n","path_anytime = path + \"_anytime\"\n","if not os.path.isdir(path_anytime):\n","    os.makedirs(path_anytime)\n","\n","# UTILS\n","print(model_class)\n","def create_cpnn():\n","    if not loss_on_seq:\n","        if not freeze_inputs_weights:\n","            return cPNN(column_class=model_class, device=device, seq_len=seq_len, train_verbose=False,\n","                        combination=combination, input_size=len(df.columns) - 2, hidden_size=hidden_size, output_size=2,\n","                        batch_size=batch_size)\n","        else:\n","            return cPNNExp(\n","                column_class=model_class,\n","                input_size=len(df.columns) - 2,\n","                hidden_size=hidden_size,\n","                output_size=2,\n","                batch_size=batch_size,\n","                device=device,\n","                seq_len=seq_len,\n","                train_verbose=False,\n","                combination=combination,\n","                remember_initial_states=rembember_initial_states,\n","            )\n","    return cPNNSeq(\n","        column_class=model_class,\n","        input_size=len(df.columns) - 2,\n","        hidden_size=hidden_size,\n","        output_size=2,\n","        batch_size=batch_size,\n","        device=device,\n","        seq_len=seq_len,\n","    )\n","\n","\n","# MAIN\n","if __name__ == \"__main__\":\n","    if args.model == \"cpnn\" and write_weights:\n","        try:\n","            df_test = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}_test.csv\"))\n","        except:\n","            pass\n","    models = []\n","    params = []\n","    inputs = []\n","    hiddens = []\n","    acc=[]\n","    kappa=[]\n","\n","    print(dataset)\n","    for i in range(1, iterations + 1):\n","        models.append([])\n","        params.append([])\n","        inputs.append([])\n","        hiddens.append([])\n","\n","        for k in perf_test:\n","            perf_test[k].append([])\n","        for k in perf_train:\n","            perf_train[k].append([])\n","        for k in perf_anytime:\n","            perf_anytime[k].append([])\n","        models[-1].append(create_cpnn())\n","        print(type(models[-1][-1].columns.columns[0]).__name__)\n","        print(f\"{i}/{iterations} iteration of {args.model}\")\n","        for task in range(1, df[\"task\"].max() + 1):\n","            acc.append([])\n","            kappa.append([])\n","            params[-1].append([])\n","            inputs[-1].append([])\n","            hiddens[-1].append([])\n","            print(\"TASK:\", task)\n","            if task > 1:\n","                if args.model == \"cpnn\":\n","                    models[-1][-1].add_new_column()\n","                elif args.model == \"multiple\":\n","                    models[-1].append(create_cpnn())\n","                elif args.model == \"single\":\n","                    models[-1].append(pickle.loads(pickle.dumps(models[-1][-1])))\n","            df_task = df[df[\"task\"] == task]\n","            df_task = df_task.drop(columns=\"task\")\n","\n","            if pretraining_samples > 0:\n","                df_pre = df_task.iloc[:pretraining_samples, 0:]\n","                df_task = df_task.iloc[pretraining_samples:, 0:]\n","                perf_pretraining = models[-1][-1].pretraining(\n","                    df_pre.iloc[0:, :-1].values.astype(np.float32),\n","                    list(df_pre.iloc[0:, -1]),\n","                    pretraining_epochs,\n","                )\n","                with open(\n","                    os.path.join(path, \"pretraining.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(perf_pretraining, f)\n","\n","            for k in perf_test:\n","                perf_test[k][-1].append([])\n","            for k in perf_train:\n","                perf_train[k][-1].append([])\n","            for k in perf_anytime:\n","                perf_anytime[k][-1].append([])\n","            if len(df_task) % batch_size == 0:\n","                n_batches = int(len(df_task) / batch_size)\n","            else:\n","                n_batches = int(len(df_task) / batch_size) + 1\n","            for i in range(0, len(df_task), batch_size):\n","                x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","                y = list(df_task.iloc[i : i + batch_size, -1])\n","                print(int(i / batch_size) + 1, \"/\", n_batches, \" batch\", end=\"\\r\")\n","                if len(y) >= seq_len:\n","                    batch_perf_test, batch_perf_anytime, batch_perf_train = models[-1][-1].test_then_train(\n","                        x, y\n","                    )\n","                    acc[-1].append([batch_perf_test['accuracy']])\n","                    kappa[-1].append([batch_perf_test['kappa']])\n","                    for k in batch_perf_test:\n","                        perf_test[k][-1][-1].append(batch_perf_test[k])\n","                    for k in batch_perf_anytime:\n","                        perf_anytime[k][-1][-1].append(batch_perf_anytime[k])\n","                    for k in batch_perf_train:\n","                        perf_train[k][-1][-1].append(batch_perf_train[k])\n","                    if args.model == \"cpnn\" and write_weights:\n","                        try:\n","                            df_test_task = df_test[df_test[\"task\"] == task].drop(\n","                                columns=\"task\"\n","                            )\n","                            x_test = df_test_task.iloc[0:500, 0:-1].values.astype(\n","                                np.float32\n","                            )\n","                            inputs[-1][-1].append(\n","                                models[-1][-1]\n","                                .columns._convert_to_tensor_dataset(x_test)\n","                                .detach()\n","                                .numpy()\n","                            )\n","                            hiddens[-1][-1].append(models[-1][-1].get_hidden(x_test))\n","                        except:\n","                            pass\n","                        params[-1][-1].append(\n","                            pickle.loads(\n","                                pickle.dumps(\n","                                    models[-1][-1]\n","                                    .columns.columns[-1]\n","                                    .lstm.weight_ih_l0.data.detach()\n","                                    .numpy()\n","                                )\n","                            )\n","                        )\n","            print()\n","            print(\n","                f\"Accuracy media sul task {task}: {np.mean(perf_test['accuracy'][-1][-1])}\"\n","            )\n","            print()\n","\n","            with open(\n","                os.path.join(path, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_test, f)\n","\n","            with open(\n","                os.path.join(path_anytime, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_anytime, f)\n","\n","            with open(\n","                os.path.join(path, \"train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_train, f)\n","            with open(os.path.join(path, \"models.pkl\"), \"wb\") as f:\n","                pickle.dump(models, f)\n","\n","            if args.model == \"cpnn\" and write_weights:\n","                with open(\n","                    os.path.join(path, \"cpnn_params.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(params, f)\n","\n","                with open(\n","                    os.path.join(path, \"inputs.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(inputs, f)\n","\n","                with open(\n","                    os.path.join(path, \"hiddens.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(hiddens, f)\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1698863205438,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"W8obMPrZrniW","outputId":"d9c433ba-d9da-41eb-fb5c-b428aba207d1"},"outputs":[{"data":{"text/plain":["array([[0.81959491],\n","       [0.64272878],\n","       [0.90241561],\n","       [0.74828695]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["np.mean(kappa, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGXbc-uC6Cq7"},"outputs":[],"source":["pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-1234.csv', index=False)\n","pd.DataFrame(kappa).to_csv('results/kappa-cpnn-16_16-1234.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2360455,"status":"ok","timestamp":1699628753720,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"zP8AkxYt_Bd7","outputId":"4c733876-2b66-4bf9-d558-02fad0c56f59"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'models.cgru.cGRULinear'>\n","sine_rw10_mode5_extended_16-16_1432\n","cGRULinear\n","1/1 iteration of cpnn\n","TASK: 1\n","\n","Accuracy media sul task 1: 0.9152933184143223\n","\n","TASK: 2\n","\n","Accuracy media sul task 2: 0.8282169117647058\n","\n","TASK: 3\n","\n","Accuracy media sul task 3: 0.9507872442455243\n","\n","TASK: 4\n","\n","Accuracy media sul task 4: 0.8776094948849105\n","\n","\n"]}],"source":["\n","# EDITABLE PARAMETERS\n","dataset = \"sine_rw10_mode5_extended_16-16_1432\"\n","\n","# OTHER PARAMETERS\n","batch_size = 128\n","hidden_size = 250\n","seq_len = 10\n","# TODO\n","iterations = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","rembember_initial_states = False\n","suffix = \"\"\n","\n","if freeze_inputs_weights:\n","    suffix += \"_exp\"\n","if combination:\n","    suffix = \"_combination\" + suffix\n","if suffix != \"\" and suffix[0:1] != \"_\":\n","    suffix = \"_\" + suffix\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\n","    \"--model\",\n","    type=str,\n","    default=\"cpnn\",\n","    help=\"Model to use: {'cpnn', 'single': cLSTM, 'multiple': mcLSTM}\",\n",")\n","parser.add_argument(\n","    \"--model_class\",\n","    type=str,\n","    default=\"cgru\",\n","    help=\"Base learner to use: {'clstm', 'cgru'}\",\n",")\n","args,_ = parser.parse_known_args()\n","\n","if args.model_class == \"clstm\":\n","    model_class = cLSTMLinear\n","else:\n","    model_class = cGRULinear\n","if hidden_size is None:\n","    if args.model_class == \"clstm\":\n","        hidden_size = 50\n","    else:\n","        hidden_size = 128\n","device = torch.device(\"cpu\")\n","df = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}.csv\"))\n","perf_test = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_train = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_anytime = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": []}\n","seq_str = \"_seq\" if loss_on_seq else \"\"\n","\n","path = os.path.join(\n","    \"performance\",\n","    f\"{dataset}/{args.model}_{args.model_class}{seq_str}{suffix}_{hidden_size}hs\",\n",")\n","if not os.path.isdir(path):\n","    os.makedirs(path)\n","\n","path_anytime = path + \"_anytime\"\n","if not os.path.isdir(path_anytime):\n","    os.makedirs(path_anytime)\n","\n","# UTILS\n","print(model_class)\n","def create_cpnn():\n","    if not loss_on_seq:\n","        if not freeze_inputs_weights:\n","            return cPNN(column_class=model_class, device=device, seq_len=seq_len, train_verbose=False,\n","                        combination=combination, input_size=len(df.columns) - 2, hidden_size=hidden_size, output_size=2,\n","                        batch_size=batch_size)\n","        else:\n","            return cPNNExp(\n","                column_class=model_class,\n","                input_size=len(df.columns) - 2,\n","                hidden_size=hidden_size,\n","                output_size=2,\n","                batch_size=batch_size,\n","                device=device,\n","                seq_len=seq_len,\n","                train_verbose=False,\n","                combination=combination,\n","                remember_initial_states=rembember_initial_states,\n","            )\n","    return cPNNSeq(\n","        column_class=model_class,\n","        input_size=len(df.columns) - 2,\n","        hidden_size=hidden_size,\n","        output_size=2,\n","        batch_size=batch_size,\n","        device=device,\n","        seq_len=seq_len,\n","    )\n","\n","\n","# MAIN\n","if __name__ == \"__main__\":\n","    if args.model == \"cpnn\" and write_weights:\n","        try:\n","            df_test = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}_test.csv\"))\n","        except:\n","            pass\n","    models = []\n","    params = []\n","    inputs = []\n","    hiddens = []\n","    acc=[]\n","    kappa=[]\n","\n","    print(dataset)\n","    for i in range(1, iterations + 1):\n","        models.append([])\n","        params.append([])\n","        inputs.append([])\n","        hiddens.append([])\n","\n","        for k in perf_test:\n","            perf_test[k].append([])\n","        for k in perf_train:\n","            perf_train[k].append([])\n","        for k in perf_anytime:\n","            perf_anytime[k].append([])\n","        models[-1].append(create_cpnn())\n","        print(type(models[-1][-1].columns.columns[0]).__name__)\n","        print(f\"{i}/{iterations} iteration of {args.model}\")\n","        for task in range(1, df[\"task\"].max() + 1):\n","            acc.append([])\n","            kappa.append([])\n","            params[-1].append([])\n","            inputs[-1].append([])\n","            hiddens[-1].append([])\n","            print(\"TASK:\", task)\n","            if task > 1:\n","                if args.model == \"cpnn\":\n","                    models[-1][-1].add_new_column()\n","                elif args.model == \"multiple\":\n","                    models[-1].append(create_cpnn())\n","                elif args.model == \"single\":\n","                    models[-1].append(pickle.loads(pickle.dumps(models[-1][-1])))\n","            df_task = df[df[\"task\"] == task]\n","            df_task = df_task.drop(columns=\"task\")\n","\n","            if pretraining_samples > 0:\n","                df_pre = df_task.iloc[:pretraining_samples, 0:]\n","                df_task = df_task.iloc[pretraining_samples:, 0:]\n","                perf_pretraining = models[-1][-1].pretraining(\n","                    df_pre.iloc[0:, :-1].values.astype(np.float32),\n","                    list(df_pre.iloc[0:, -1]),\n","                    pretraining_epochs,\n","                )\n","                with open(\n","                    os.path.join(path, \"pretraining.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(perf_pretraining, f)\n","\n","            for k in perf_test:\n","                perf_test[k][-1].append([])\n","            for k in perf_train:\n","                perf_train[k][-1].append([])\n","            for k in perf_anytime:\n","                perf_anytime[k][-1].append([])\n","            if len(df_task) % batch_size == 0:\n","                n_batches = int(len(df_task) / batch_size)\n","            else:\n","                n_batches = int(len(df_task) / batch_size) + 1\n","            for i in range(0, len(df_task), batch_size):\n","                x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","                y = list(df_task.iloc[i : i + batch_size, -1])\n","                print(int(i / batch_size) + 1, \"/\", n_batches, \" batch\", end=\"\\r\")\n","                if len(y) >= seq_len:\n","                    batch_perf_test, batch_perf_anytime, batch_perf_train = models[-1][-1].test_then_train(\n","                        x, y\n","                    )\n","                    acc[-1].append([batch_perf_test['accuracy']])\n","                    kappa[-1].append([batch_perf_test['kappa']])\n","                    for k in batch_perf_test:\n","                        perf_test[k][-1][-1].append(batch_perf_test[k])\n","                    for k in batch_perf_anytime:\n","                        perf_anytime[k][-1][-1].append(batch_perf_anytime[k])\n","                    for k in batch_perf_train:\n","                        perf_train[k][-1][-1].append(batch_perf_train[k])\n","                    if args.model == \"cpnn\" and write_weights:\n","                        try:\n","                            df_test_task = df_test[df_test[\"task\"] == task].drop(\n","                                columns=\"task\"\n","                            )\n","                            x_test = df_test_task.iloc[0:500, 0:-1].values.astype(\n","                                np.float32\n","                            )\n","                            inputs[-1][-1].append(\n","                                models[-1][-1]\n","                                .columns._convert_to_tensor_dataset(x_test)\n","                                .detach()\n","                                .numpy()\n","                            )\n","                            hiddens[-1][-1].append(models[-1][-1].get_hidden(x_test))\n","                        except:\n","                            pass\n","                        params[-1][-1].append(\n","                            pickle.loads(\n","                                pickle.dumps(\n","                                    models[-1][-1]\n","                                    .columns.columns[-1]\n","                                    .lstm.weight_ih_l0.data.detach()\n","                                    .numpy()\n","                                )\n","                            )\n","                        )\n","            print()\n","            print(\n","                f\"Accuracy media sul task {task}: {np.mean(perf_test['accuracy'][-1][-1])}\"\n","            )\n","            print()\n","\n","            with open(\n","                os.path.join(path, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_test, f)\n","\n","            with open(\n","                os.path.join(path_anytime, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_anytime, f)\n","\n","            with open(\n","                os.path.join(path, \"train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_train, f)\n","            with open(os.path.join(path, \"models.pkl\"), \"wb\") as f:\n","                pickle.dump(models, f)\n","\n","            if args.model == \"cpnn\" and write_weights:\n","                with open(\n","                    os.path.join(path, \"cpnn_params.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(params, f)\n","\n","                with open(\n","                    os.path.join(path, \"inputs.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(inputs, f)\n","\n","                with open(\n","                    os.path.join(path, \"hiddens.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(hiddens, f)\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JdxK9wcF_BOW"},"outputs":[],"source":["pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-1432.csv', index=False)\n","pd.DataFrame(kappa).to_csv('results/kappa-cpnn-16_16-1432.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2323907,"status":"ok","timestamp":1699631078501,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"ED6Oira__BFt","outputId":"9cd7e297-123a-464f-8b99-383954864637"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'models.cgru.cGRULinear'>\n","sine_rw10_mode5_extended_16-16_2341\n","cGRULinear\n","1/1 iteration of cpnn\n","TASK: 1\n","\n","Accuracy media sul task 1: 0.8098984974424553\n","\n","TASK: 2\n","\n","Accuracy media sul task 2: 0.8889426150895141\n","\n","TASK: 3\n","\n","Accuracy media sul task 3: 0.8734454923273657\n","\n","TASK: 4\n","\n","Accuracy media sul task 4: 0.9525095907928388\n","\n","\n"]}],"source":["\n","# EDITABLE PARAMETERS\n","dataset = \"sine_rw10_mode5_extended_16-16_2341\"\n","\n","# OTHER PARAMETERS\n","batch_size = 128\n","hidden_size = 250\n","seq_len = 10\n","# TODO\n","iterations = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","rembember_initial_states = False\n","suffix = \"\"\n","\n","if freeze_inputs_weights:\n","    suffix += \"_exp\"\n","if combination:\n","    suffix = \"_combination\" + suffix\n","if suffix != \"\" and suffix[0:1] != \"_\":\n","    suffix = \"_\" + suffix\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\n","    \"--model\",\n","    type=str,\n","    default=\"cpnn\",\n","    help=\"Model to use: {'cpnn', 'single': cLSTM, 'multiple': mcLSTM}\",\n",")\n","parser.add_argument(\n","    \"--model_class\",\n","    type=str,\n","    default=\"cgru\",\n","    help=\"Base learner to use: {'clstm', 'cgru'}\",\n",")\n","args,_ = parser.parse_known_args()\n","\n","if args.model_class == \"clstm\":\n","    model_class = cLSTMLinear\n","else:\n","    model_class = cGRULinear\n","if hidden_size is None:\n","    if args.model_class == \"clstm\":\n","        hidden_size = 50\n","    else:\n","        hidden_size = 128\n","device = torch.device(\"cpu\")\n","df = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}.csv\"))\n","perf_test = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_train = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_anytime = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": []}\n","seq_str = \"_seq\" if loss_on_seq else \"\"\n","\n","path = os.path.join(\n","    \"performance\",\n","    f\"{dataset}/{args.model}_{args.model_class}{seq_str}{suffix}_{hidden_size}hs\",\n",")\n","if not os.path.isdir(path):\n","    os.makedirs(path)\n","\n","path_anytime = path + \"_anytime\"\n","if not os.path.isdir(path_anytime):\n","    os.makedirs(path_anytime)\n","\n","# UTILS\n","print(model_class)\n","def create_cpnn():\n","    if not loss_on_seq:\n","        if not freeze_inputs_weights:\n","            return cPNN(column_class=model_class, device=device, seq_len=seq_len, train_verbose=False,\n","                        combination=combination, input_size=len(df.columns) - 2, hidden_size=hidden_size, output_size=2,\n","                        batch_size=batch_size)\n","        else:\n","            return cPNNExp(\n","                column_class=model_class,\n","                input_size=len(df.columns) - 2,\n","                hidden_size=hidden_size,\n","                output_size=2,\n","                batch_size=batch_size,\n","                device=device,\n","                seq_len=seq_len,\n","                train_verbose=False,\n","                combination=combination,\n","                remember_initial_states=rembember_initial_states,\n","            )\n","    return cPNNSeq(\n","        column_class=model_class,\n","        input_size=len(df.columns) - 2,\n","        hidden_size=hidden_size,\n","        output_size=2,\n","        batch_size=batch_size,\n","        device=device,\n","        seq_len=seq_len,\n","    )\n","\n","\n","# MAIN\n","if __name__ == \"__main__\":\n","    if args.model == \"cpnn\" and write_weights:\n","        try:\n","            df_test = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}_test.csv\"))\n","        except:\n","            pass\n","    models = []\n","    params = []\n","    inputs = []\n","    hiddens = []\n","    acc=[]\n","    kappa=[]\n","\n","    print(dataset)\n","    for i in range(1, iterations + 1):\n","        models.append([])\n","        params.append([])\n","        inputs.append([])\n","        hiddens.append([])\n","\n","        for k in perf_test:\n","            perf_test[k].append([])\n","        for k in perf_train:\n","            perf_train[k].append([])\n","        for k in perf_anytime:\n","            perf_anytime[k].append([])\n","        models[-1].append(create_cpnn())\n","        print(type(models[-1][-1].columns.columns[0]).__name__)\n","        print(f\"{i}/{iterations} iteration of {args.model}\")\n","        for task in range(1, df[\"task\"].max() + 1):\n","            acc.append([])\n","            kappa.append([])\n","            params[-1].append([])\n","            inputs[-1].append([])\n","            hiddens[-1].append([])\n","            print(\"TASK:\", task)\n","            if task > 1:\n","                if args.model == \"cpnn\":\n","                    models[-1][-1].add_new_column()\n","                elif args.model == \"multiple\":\n","                    models[-1].append(create_cpnn())\n","                elif args.model == \"single\":\n","                    models[-1].append(pickle.loads(pickle.dumps(models[-1][-1])))\n","            df_task = df[df[\"task\"] == task]\n","            df_task = df_task.drop(columns=\"task\")\n","\n","            if pretraining_samples > 0:\n","                df_pre = df_task.iloc[:pretraining_samples, 0:]\n","                df_task = df_task.iloc[pretraining_samples:, 0:]\n","                perf_pretraining = models[-1][-1].pretraining(\n","                    df_pre.iloc[0:, :-1].values.astype(np.float32),\n","                    list(df_pre.iloc[0:, -1]),\n","                    pretraining_epochs,\n","                )\n","                with open(\n","                    os.path.join(path, \"pretraining.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(perf_pretraining, f)\n","\n","            for k in perf_test:\n","                perf_test[k][-1].append([])\n","            for k in perf_train:\n","                perf_train[k][-1].append([])\n","            for k in perf_anytime:\n","                perf_anytime[k][-1].append([])\n","            if len(df_task) % batch_size == 0:\n","                n_batches = int(len(df_task) / batch_size)\n","            else:\n","                n_batches = int(len(df_task) / batch_size) + 1\n","            for i in range(0, len(df_task), batch_size):\n","                x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","                y = list(df_task.iloc[i : i + batch_size, -1])\n","                print(int(i / batch_size) + 1, \"/\", n_batches, \" batch\", end=\"\\r\")\n","                if len(y) >= seq_len:\n","                    batch_perf_test, batch_perf_anytime, batch_perf_train = models[-1][-1].test_then_train(\n","                        x, y\n","                    )\n","                    acc[-1].append([batch_perf_test['accuracy']])\n","                    kappa[-1].append([batch_perf_test['kappa']])\n","                    for k in batch_perf_test:\n","                        perf_test[k][-1][-1].append(batch_perf_test[k])\n","                    for k in batch_perf_anytime:\n","                        perf_anytime[k][-1][-1].append(batch_perf_anytime[k])\n","                    for k in batch_perf_train:\n","                        perf_train[k][-1][-1].append(batch_perf_train[k])\n","                    if args.model == \"cpnn\" and write_weights:\n","                        try:\n","                            df_test_task = df_test[df_test[\"task\"] == task].drop(\n","                                columns=\"task\"\n","                            )\n","                            x_test = df_test_task.iloc[0:500, 0:-1].values.astype(\n","                                np.float32\n","                            )\n","                            inputs[-1][-1].append(\n","                                models[-1][-1]\n","                                .columns._convert_to_tensor_dataset(x_test)\n","                                .detach()\n","                                .numpy()\n","                            )\n","                            hiddens[-1][-1].append(models[-1][-1].get_hidden(x_test))\n","                        except:\n","                            pass\n","                        params[-1][-1].append(\n","                            pickle.loads(\n","                                pickle.dumps(\n","                                    models[-1][-1]\n","                                    .columns.columns[-1]\n","                                    .lstm.weight_ih_l0.data.detach()\n","                                    .numpy()\n","                                )\n","                            )\n","                        )\n","            print()\n","            print(\n","                f\"Accuracy media sul task {task}: {np.mean(perf_test['accuracy'][-1][-1])}\"\n","            )\n","            print()\n","\n","            with open(\n","                os.path.join(path, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_test, f)\n","\n","            with open(\n","                os.path.join(path_anytime, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_anytime, f)\n","\n","            with open(\n","                os.path.join(path, \"train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_train, f)\n","            with open(os.path.join(path, \"models.pkl\"), \"wb\") as f:\n","                pickle.dump(models, f)\n","\n","            if args.model == \"cpnn\" and write_weights:\n","                with open(\n","                    os.path.join(path, \"cpnn_params.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(params, f)\n","\n","                with open(\n","                    os.path.join(path, \"inputs.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(inputs, f)\n","\n","                with open(\n","                    os.path.join(path, \"hiddens.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(hiddens, f)\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpGJSnh6_A8G"},"outputs":[],"source":["pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-2341.csv', index=False)\n","pd.DataFrame(kappa).to_csv('results/kappa-cpnn-16_16-2341.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2430205,"status":"ok","timestamp":1699644925196,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"4qFJKQrF_Awx","outputId":"e376bcb1-6bfa-47bf-d2f6-bba467f908a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'models.cgru.cGRULinear'>\n","sine_rw10_mode5_extended_16-16_2143\n","cGRULinear\n","1/1 iteration of cpnn\n","TASK: 1\n","\n","Accuracy media sul task 1: 0.8116528132992327\n","\n","TASK: 2\n","\n","Accuracy media sul task 2: 0.8892223465473147\n","\n","TASK: 3\n","\n","Accuracy media sul task 3: 0.8701326726342711\n","\n","TASK: 4\n","\n","Accuracy media sul task 4: 0.935789641943734\n","\n","\n"]}],"source":["\n","# EDITABLE PARAMETERS\n","dataset = \"sine_rw10_mode5_extended_16-16_2143\"\n","\n","# OTHER PARAMETERS\n","batch_size = 128\n","hidden_size = 250\n","seq_len = 10\n","# TODO\n","iterations = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","rembember_initial_states = False\n","suffix = \"\"\n","\n","if freeze_inputs_weights:\n","    suffix += \"_exp\"\n","if combination:\n","    suffix = \"_combination\" + suffix\n","if suffix != \"\" and suffix[0:1] != \"_\":\n","    suffix = \"_\" + suffix\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\n","    \"--model\",\n","    type=str,\n","    default=\"cpnn\",\n","    help=\"Model to use: {'cpnn', 'single': cLSTM, 'multiple': mcLSTM}\",\n",")\n","parser.add_argument(\n","    \"--model_class\",\n","    type=str,\n","    default=\"cgru\",\n","    help=\"Base learner to use: {'clstm', 'cgru'}\",\n",")\n","args,_ = parser.parse_known_args()\n","\n","if args.model_class == \"clstm\":\n","    model_class = cLSTMLinear\n","else:\n","    model_class = cGRULinear\n","if hidden_size is None:\n","    if args.model_class == \"clstm\":\n","        hidden_size = 50\n","    else:\n","        hidden_size = 128\n","device = torch.device(\"cpu\")\n","df = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}.csv\"))\n","perf_test = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_train = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_anytime = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": []}\n","seq_str = \"_seq\" if loss_on_seq else \"\"\n","\n","path = os.path.join(\n","    \"performance\",\n","    f\"{dataset}/{args.model}_{args.model_class}{seq_str}{suffix}_{hidden_size}hs\",\n",")\n","if not os.path.isdir(path):\n","    os.makedirs(path)\n","\n","path_anytime = path + \"_anytime\"\n","if not os.path.isdir(path_anytime):\n","    os.makedirs(path_anytime)\n","\n","# UTILS\n","print(model_class)\n","def create_cpnn():\n","    if not loss_on_seq:\n","        if not freeze_inputs_weights:\n","            return cPNN(column_class=model_class, device=device, seq_len=seq_len, train_verbose=False,\n","                        combination=combination, input_size=len(df.columns) - 2, hidden_size=hidden_size, output_size=2,\n","                        batch_size=batch_size)\n","        else:\n","            return cPNNExp(\n","                column_class=model_class,\n","                input_size=len(df.columns) - 2,\n","                hidden_size=hidden_size,\n","                output_size=2,\n","                batch_size=batch_size,\n","                device=device,\n","                seq_len=seq_len,\n","                train_verbose=False,\n","                combination=combination,\n","                remember_initial_states=rembember_initial_states,\n","            )\n","    return cPNNSeq(\n","        column_class=model_class,\n","        input_size=len(df.columns) - 2,\n","        hidden_size=hidden_size,\n","        output_size=2,\n","        batch_size=batch_size,\n","        device=device,\n","        seq_len=seq_len,\n","    )\n","\n","\n","# MAIN\n","if __name__ == \"__main__\":\n","    if args.model == \"cpnn\" and write_weights:\n","        try:\n","            df_test = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}_test.csv\"))\n","        except:\n","            pass\n","    models = []\n","    params = []\n","    inputs = []\n","    hiddens = []\n","    acc=[]\n","    kappa=[]\n","\n","    print(dataset)\n","    for i in range(1, iterations + 1):\n","        models.append([])\n","        params.append([])\n","        inputs.append([])\n","        hiddens.append([])\n","\n","        for k in perf_test:\n","            perf_test[k].append([])\n","        for k in perf_train:\n","            perf_train[k].append([])\n","        for k in perf_anytime:\n","            perf_anytime[k].append([])\n","        models[-1].append(create_cpnn())\n","        print(type(models[-1][-1].columns.columns[0]).__name__)\n","        print(f\"{i}/{iterations} iteration of {args.model}\")\n","        for task in range(1, df[\"task\"].max() + 1):\n","            acc.append([])\n","            kappa.append([])\n","            params[-1].append([])\n","            inputs[-1].append([])\n","            hiddens[-1].append([])\n","            print(\"TASK:\", task)\n","            if task > 1:\n","                if args.model == \"cpnn\":\n","                    models[-1][-1].add_new_column()\n","                elif args.model == \"multiple\":\n","                    models[-1].append(create_cpnn())\n","                elif args.model == \"single\":\n","                    models[-1].append(pickle.loads(pickle.dumps(models[-1][-1])))\n","            df_task = df[df[\"task\"] == task]\n","            df_task = df_task.drop(columns=\"task\")\n","\n","            if pretraining_samples > 0:\n","                df_pre = df_task.iloc[:pretraining_samples, 0:]\n","                df_task = df_task.iloc[pretraining_samples:, 0:]\n","                perf_pretraining = models[-1][-1].pretraining(\n","                    df_pre.iloc[0:, :-1].values.astype(np.float32),\n","                    list(df_pre.iloc[0:, -1]),\n","                    pretraining_epochs,\n","                )\n","                with open(\n","                    os.path.join(path, \"pretraining.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(perf_pretraining, f)\n","\n","            for k in perf_test:\n","                perf_test[k][-1].append([])\n","            for k in perf_train:\n","                perf_train[k][-1].append([])\n","            for k in perf_anytime:\n","                perf_anytime[k][-1].append([])\n","            if len(df_task) % batch_size == 0:\n","                n_batches = int(len(df_task) / batch_size)\n","            else:\n","                n_batches = int(len(df_task) / batch_size) + 1\n","            for i in range(0, len(df_task), batch_size):\n","                x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","                y = list(df_task.iloc[i : i + batch_size, -1])\n","                print(int(i / batch_size) + 1, \"/\", n_batches, \" batch\", end=\"\\r\")\n","                if len(y) >= seq_len:\n","                    batch_perf_test, batch_perf_anytime, batch_perf_train = models[-1][-1].test_then_train(\n","                        x, y\n","                    )\n","                    acc[-1].append([batch_perf_test['accuracy']])\n","                    kappa[-1].append([batch_perf_test['kappa']])\n","                    for k in batch_perf_test:\n","                        perf_test[k][-1][-1].append(batch_perf_test[k])\n","                    for k in batch_perf_anytime:\n","                        perf_anytime[k][-1][-1].append(batch_perf_anytime[k])\n","                    for k in batch_perf_train:\n","                        perf_train[k][-1][-1].append(batch_perf_train[k])\n","                    if args.model == \"cpnn\" and write_weights:\n","                        try:\n","                            df_test_task = df_test[df_test[\"task\"] == task].drop(\n","                                columns=\"task\"\n","                            )\n","                            x_test = df_test_task.iloc[0:500, 0:-1].values.astype(\n","                                np.float32\n","                            )\n","                            inputs[-1][-1].append(\n","                                models[-1][-1]\n","                                .columns._convert_to_tensor_dataset(x_test)\n","                                .detach()\n","                                .numpy()\n","                            )\n","                            hiddens[-1][-1].append(models[-1][-1].get_hidden(x_test))\n","                        except:\n","                            pass\n","                        params[-1][-1].append(\n","                            pickle.loads(\n","                                pickle.dumps(\n","                                    models[-1][-1]\n","                                    .columns.columns[-1]\n","                                    .lstm.weight_ih_l0.data.detach()\n","                                    .numpy()\n","                                )\n","                            )\n","                        )\n","            print()\n","            print(\n","                f\"Accuracy media sul task {task}: {np.mean(perf_test['accuracy'][-1][-1])}\"\n","            )\n","            print()\n","\n","            with open(\n","                os.path.join(path, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_test, f)\n","\n","            with open(\n","                os.path.join(path_anytime, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_anytime, f)\n","\n","            with open(\n","                os.path.join(path, \"train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_train, f)\n","            with open(os.path.join(path, \"models.pkl\"), \"wb\") as f:\n","                pickle.dump(models, f)\n","\n","            if args.model == \"cpnn\" and write_weights:\n","                with open(\n","                    os.path.join(path, \"cpnn_params.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(params, f)\n","\n","                with open(\n","                    os.path.join(path, \"inputs.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(inputs, f)\n","\n","                with open(\n","                    os.path.join(path, \"hiddens.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(hiddens, f)\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl8E6ThF_AjR"},"outputs":[],"source":["pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-2143.csv', index=False)\n","pd.DataFrame(kappa).to_csv('results/kappa-cpnn-16_16-2143.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U5Sqcnvd_AIC"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"SPeE-nJDQPvt"},"source":["##This is for running CPNN with gru and pretrain model based on train data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YRP85JMtI3fq","outputId":"409ddfff-bfc8-4715-f940-9b9fc2baa3dc"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-9-817a95694dfa>:56: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df = pretrain_data.append(df, ignore_index=True)\n"]},{"name":"stdout","output_type":"stream","text":["<class 'models.cgru.cGRULinear'>\n","sine_rw10_mode5_extended_16-16_2143\n","cGRULinear\n","1/1 iteration of cpnn\n","TASK: 0\n","\n","Accuracy media sul task 0: 0.8893662084398977\n","\n","TASK: 1\n","\n","Accuracy media sul task 1: 0.8658967391304349\n","\n","TASK: 2\n","\n","Accuracy media sul task 2: 0.8124760230179029\n","\n","TASK: 3\n","\n","Accuracy media sul task 3: 0.8898937020460358\n","\n","TASK: 4\n"]},{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy media sul task 4: 0.8687140345268543\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-9-817a95694dfa>\", line 225, in <cell line: 106>\n","    with open(\n","OSError: [Errno 107] Transport endpoint is not connected: 'performance/sine_rw10_mode5_extended_16-16_2143/cpnn_cgru_250hs/test_then_train.pkl'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-9-817a95694dfa>\", line 225, in <cell line: 106>\n","    with open(\n","OSError: [Errno 107] Transport endpoint is not connected: 'performance/sine_rw10_mode5_extended_16-16_2143/cpnn_cgru_250hs/test_then_train.pkl'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-9-817a95694dfa>\", line 225, in <cell line: 106>\n","    with open(\n","OSError: [Errno 107] Transport endpoint is not connected: 'performance/sine_rw10_mode5_extended_16-16_2143/cpnn_cgru_250hs/test_then_train.pkl'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["\n","# EDITABLE PARAMETERS\n","dataset1 = \"sine_rw10_mode5_extended_6-6_1234\"\n","pretrain_data = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset1}.csv\"))\n","pretrain_data = pretrain_data[pretrain_data[\"task\"] == 4]\n","pretrain_data.loc[:, 'task'] = 0\n","dataset2 = \"sine_rw10_mode5_extended_16-16_2143\"\n","\n","# OTHER PARAMETERS\n","batch_size = 128\n","hidden_size = 250\n","seq_len = 10\n","# TODO\n","iterations = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","rembember_initial_states = False\n","suffix = \"\"\n","\n","if freeze_inputs_weights:\n","    suffix += \"_exp\"\n","if combination:\n","    suffix = \"_combination\" + suffix\n","if suffix != \"\" and suffix[0:1] != \"_\":\n","    suffix = \"_\" + suffix\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\n","    \"--model\",\n","    type=str,\n","    default=\"cpnn\",\n","    help=\"Model to use: {'cpnn', 'single': cLSTM, 'multiple': mcLSTM}\",\n",")\n","parser.add_argument(\n","    \"--model_class\",\n","    type=str,\n","    default=\"cgru\",\n","    help=\"Base learner to use: {'clstm', 'cgru'}\",\n",")\n","args,_ = parser.parse_known_args()\n","\n","if args.model_class == \"clstm\":\n","    model_class = cLSTMLinear\n","else:\n","    model_class = cGRULinear\n","if hidden_size is None:\n","    if args.model_class == \"clstm\":\n","        hidden_size = 50\n","    else:\n","        hidden_size = 128\n","device = torch.device(\"cpu\")\n","df = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset2}.csv\"))\n","\n","df = pretrain_data.append(df, ignore_index=True)\n","perf_test = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_train = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_anytime = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": []}\n","seq_str = \"_seq\" if loss_on_seq else \"\"\n","\n","path = os.path.join(\n","    \"performance\",\n","    f\"{dataset2}/{args.model}_{args.model_class}{seq_str}{suffix}_{hidden_size}hs\",\n",")\n","if not os.path.isdir(path):\n","    os.makedirs(path)\n","\n","path_anytime = path + \"_anytime\"\n","if not os.path.isdir(path_anytime):\n","    os.makedirs(path_anytime)\n","\n","# UTILS\n","print(model_class)\n","def create_cpnn():\n","    if not loss_on_seq:\n","        if not freeze_inputs_weights:\n","            return cPNN(column_class=model_class, device=device, seq_len=seq_len, train_verbose=False,\n","                        combination=combination, input_size=len(df.columns) - 2, hidden_size=hidden_size, output_size=2,\n","                        batch_size=batch_size)\n","        else:\n","            return cPNNExp(\n","                column_class=model_class,\n","                input_size=len(df.columns) - 2,\n","                hidden_size=hidden_size,\n","                output_size=2,\n","                batch_size=batch_size,\n","                device=device,\n","                seq_len=seq_len,\n","                train_verbose=False,\n","                combination=combination,\n","                remember_initial_states=rembember_initial_states,\n","            )\n","    return cPNNSeq(\n","        column_class=model_class,\n","        input_size=len(df.columns) - 2,\n","        hidden_size=hidden_size,\n","        output_size=2,\n","        batch_size=batch_size,\n","        device=device,\n","        seq_len=seq_len,\n","    )\n","\n","\n","# MAIN\n","if __name__ == \"__main__\":\n","    if args.model == \"cpnn\" and write_weights:\n","        try:\n","            df_test = pd.read_csv(os.path.join(\"datasets/datasets\", f\"{dataset}_test.csv\"))\n","        except:\n","            pass\n","    models = []\n","    params = []\n","    inputs = []\n","    hiddens = []\n","    acc=[]\n","    kappa=[]\n","\n","    print(dataset2)\n","    for i in range(1, iterations + 1):\n","        models.append([])\n","        params.append([])\n","        inputs.append([])\n","        hiddens.append([])\n","\n","        for k in perf_test:\n","            perf_test[k].append([])\n","        for k in perf_train:\n","            perf_train[k].append([])\n","        for k in perf_anytime:\n","            perf_anytime[k].append([])\n","        models[-1].append(create_cpnn())\n","        print(type(models[-1][-1].columns.columns[0]).__name__)\n","        print(f\"{i}/{iterations} iteration of {args.model}\")\n","        for task in range(0, df[\"task\"].max() + 1):\n","            acc.append([])\n","            kappa.append([])\n","            params[-1].append([])\n","            inputs[-1].append([])\n","            hiddens[-1].append([])\n","            print(\"TASK:\", task)\n","            if task > 0:\n","                if args.model == \"cpnn\":\n","                    models[-1][-1].add_new_column()\n","                elif args.model == \"multiple\":\n","                    models[-1].append(create_cpnn())\n","                elif args.model == \"single\":\n","                    models[-1].append(pickle.loads(pickle.dumps(models[-1][-1])))\n","            df_task = df[df[\"task\"] == task]\n","            #df_task.loc[:, 'task'] = 1\n","            df_task = df_task.drop(columns=\"task\")\n","            if pretraining_samples > 0:\n","                df_pre = df_task.iloc[:pretraining_samples, 0:]\n","                df_task = df_task.iloc[pretraining_samples:, 0:]\n","                perf_pretraining = models[-1][-1].pretraining(\n","                    df_pre.iloc[0:, :-1].values.astype(np.float32),\n","                    list(df_pre.iloc[0:, -1]),\n","                    pretraining_epochs,\n","                )\n","                with open(\n","                    os.path.join(path, \"pretraining.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(perf_pretraining, f)\n","\n","            for k in perf_test:\n","                perf_test[k][-1].append([])\n","            for k in perf_train:\n","                perf_train[k][-1].append([])\n","            for k in perf_anytime:\n","                perf_anytime[k][-1].append([])\n","            if len(df_task) % batch_size == 0:\n","                n_batches = int(len(df_task) / batch_size)\n","            else:\n","                n_batches = int(len(df_task) / batch_size) + 1\n","            for i in range(0, len(df_task), batch_size):\n","                x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","                y = list(df_task.iloc[i : i + batch_size, -1])\n","                print(int(i / batch_size) + 1, \"/\", n_batches, \" batch\", end=\"\\r\")\n","                if len(y) >= seq_len:\n","                    batch_perf_test, batch_perf_anytime, batch_perf_train = models[-1][-1].test_then_train(\n","                        x, y\n","                    )\n","                    acc[-1].append([batch_perf_test['accuracy']])\n","                    kappa[-1].append([batch_perf_test['kappa']])\n","                    for k in batch_perf_test:\n","                        perf_test[k][-1][-1].append(batch_perf_test[k])\n","                    for k in batch_perf_anytime:\n","                        perf_anytime[k][-1][-1].append(batch_perf_anytime[k])\n","                    for k in batch_perf_train:\n","                        perf_train[k][-1][-1].append(batch_perf_train[k])\n","                    if args.model == \"cpnn\" and write_weights:\n","                        try:\n","                            df_test_task = df_test[df_test[\"task\"] == task].drop(\n","                                columns=\"task\"\n","                            )\n","                            x_test = df_test_task.iloc[0:500, 0:-1].values.astype(\n","                                np.float32\n","                            )\n","                            inputs[-1][-1].append(\n","                                models[-1][-1]\n","                                .columns._convert_to_tensor_dataset(x_test)\n","                                .detach()\n","                                .numpy()\n","                            )\n","                            hiddens[-1][-1].append(models[-1][-1].get_hidden(x_test))\n","                        except:\n","                            pass\n","                        params[-1][-1].append(\n","                            pickle.loads(\n","                                pickle.dumps(\n","                                    models[-1][-1]\n","                                    .columns.columns[-1]\n","                                    .lstm.weight_ih_l0.data.detach()\n","                                    .numpy()\n","                                )\n","                            )\n","                        )\n","            print()\n","            print(\n","                f\"Accuracy media sul task {task}: {np.mean(perf_test['accuracy'][-1][-1])}\"\n","            )\n","            print()\n","\n","            with open(\n","                os.path.join(path, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_test, f)\n","\n","            with open(\n","                os.path.join(path_anytime, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_anytime, f)\n","\n","            with open(\n","                os.path.join(path, \"train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_train, f)\n","            with open(os.path.join(path, \"models.pkl\"), \"wb\") as f:\n","                pickle.dump(models, f)\n","\n","            if args.model == \"cpnn\" and write_weights:\n","                with open(\n","                    os.path.join(path, \"cpnn_params.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(params, f)\n","\n","                with open(\n","                    os.path.join(path, \"inputs.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(inputs, f)\n","\n","                with open(\n","                    os.path.join(path, \"hiddens.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(hiddens, f)\n","        print()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TetdePx3YRce","outputId":"dc5dccb9-6de1-4d40-c4f3-3b56ebf700dd"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-9-6124e6faaa4a>\", line 1, in <cell line: 1>\n","    pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-2143-pretrain-t4.csv', index=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 3720, in to_csv\n","    return DataFrameRenderer(formatter).to_csv(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\", line 1189, in to_csv\n","    csv_formatter.save()\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\", line 241, in save\n","    with get_handle(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 734, in get_handle\n","    check_parent_directory(str(handle))\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 596, in check_parent_directory\n","    if not parent.is_dir():\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1305, in is_dir\n","    return S_ISDIR(self.stat().st_mode)\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1097, in stat\n","    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n","OSError: [Errno 107] Transport endpoint is not connected: 'results'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-9-6124e6faaa4a>\", line 1, in <cell line: 1>\n","    pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-2143-pretrain-t4.csv', index=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 3720, in to_csv\n","    return DataFrameRenderer(formatter).to_csv(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\", line 1189, in to_csv\n","    csv_formatter.save()\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\", line 241, in save\n","    with get_handle(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 734, in get_handle\n","    check_parent_directory(str(handle))\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 596, in check_parent_directory\n","    if not parent.is_dir():\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1305, in is_dir\n","    return S_ISDIR(self.stat().st_mode)\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1097, in stat\n","    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n","OSError: [Errno 107] Transport endpoint is not connected: 'results'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]},{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-9-6124e6faaa4a>\", line 1, in <cell line: 1>\n","    pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-2143-pretrain-t4.csv', index=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 3720, in to_csv\n","    return DataFrameRenderer(formatter).to_csv(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\", line 1189, in to_csv\n","    csv_formatter.save()\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\", line 241, in save\n","    with get_handle(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 734, in get_handle\n","    check_parent_directory(str(handle))\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 596, in check_parent_directory\n","    if not parent.is_dir():\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1305, in is_dir\n","    return S_ISDIR(self.stat().st_mode)\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1097, in stat\n","    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n","OSError: [Errno 107] Transport endpoint is not connected: 'results'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["pd.DataFrame(acc).to_csv('results/acc-cpnn-16_16-2143-pretrain-t4.csv', index=False)\n","pd.DataFrame(kappa).to_csv('results/kappa-cpnn-16_16-2143-pretrain-t4.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R715JeeCwl9y"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWWNCkO1wmtn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uL_XZGKqwm7t"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvJxCZXpwnJn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdYnMno_gRo6"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuFIbQm2CzZaMgluH0gsTs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}