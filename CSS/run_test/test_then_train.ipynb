{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1MekYNjmV6BysweTeiVxzPsoJ1rAjrJi1","authorship_tag":"ABX9TyNrSa97xISkuddUlsLoyEVz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jDhzhuvZWA7","executionInfo":{"status":"ok","timestamp":1692005339551,"user_tz":-120,"elapsed":17774,"user":{"displayName":"reza paki","userId":"01979157922216683878"}},"outputId":"408dc1eb-19be-4979-bcf3-164df6d1b119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd drive/My Drive/Thesis/CPNN/cpnn\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JiyoZO0RZbiq","executionInfo":{"status":"ok","timestamp":1692005403948,"user_tz":-120,"elapsed":658,"user":{"displayName":"reza paki","userId":"01979157922216683878"}},"outputId":"15764515-7aef-4651-8c25-ea4dafe61e3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Thesis/CPNN/cpnn\n","data  datasets\tlab  models  README.md\trequirements.txt  run_test\n"]}]},{"cell_type":"code","source":["%run -i \"models/clstm.py\"\n","%run -i \"models/cpnn.py\"\n","%run -i \"models/cpnn_others.py\"\n","%run -i \"models/cpnn_seq.py\"\n","%run -i \"models/cpnn_columns\"\n","%run -i \"models/cgru.py\"\n","%run -i \"models/clstm.py\"\n"],"metadata":{"id":"qI2fGpE-bpXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5Jo_joUYS6s"},"outputs":[],"source":["# IMPORT\n","import os\n","from models.cpnn import *\n","from models.cpnn_others import cPNNExp\n","from models.cpnn_seq import cPNNSeq\n","from models.cgru import cGRULinear\n","from models.clstm import *\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import argparse"]},{"cell_type":"code","source":["import sys\n","sys.path.append('drive/My Drive/Thesis/CPNN/cpnn')"],"metadata":{"id":"hiMOBtegeZkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# EDITABLE PARAMETERS\n","dataset = \"sine_rw_10_1234\"\n","\n","# OTHER PARAMETERS\n","batch_size = 128\n","hidden_size = 50\n","seq_len = 10\n","# TODO\n","iterations = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","rembember_initial_states = False\n","suffix = \"\"\n","\n","if freeze_inputs_weights:\n","    suffix += \"_exp\"\n","if combination:\n","    suffix = \"_combination\" + suffix\n","if suffix != \"\" and suffix[0:1] != \"_\":\n","    suffix = \"_\" + suffix\n","parser = argparse.ArgumentParser()\n","\n","parser.add_argument(\n","    \"--model\",\n","    type=str,\n","    default=\"cpnn\",\n","    help=\"Model to use: {'cpnn', 'single': cLSTM, 'multiple': mcLSTM}\",\n",")\n","parser.add_argument(\n","    \"--model_class\",\n","    type=str,\n","    default=\"clstm\",\n","    help=\"Base learner to use: {'clstm', 'cgru'}\",\n",")\n","\n","args,_ = parser.parse_known_args()\n","\n","if args.model_class == \"clstm\":\n","\n","    model_class = cLSTMLinear\n","\n","else:\n","    model_class = cGRULinear\n","if hidden_size is None:\n","    if args.model_class == \"clstm\":\n","        hidden_size = 50\n","    else:\n","        hidden_size = 128\n","\n","device = torch.device(\"cpu\")\n","df = pd.read_csv(os.path.join(\"datasets\", f\"{dataset}.csv\"))\n","perf_test = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_train = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": [], \"loss\": []}\n","perf_anytime = {\"accuracy\": [], \"kappa\": [], \"kappa_temporal\": []}\n","seq_str = \"_seq\" if loss_on_seq else \"\"\n","\n","path = os.path.join(\n","    \"performance\",\n","    f\"{dataset}/{args.model}_{args.model_class}{seq_str}{suffix}_{hidden_size}hs\",\n",")\n","if not os.path.isdir(path):\n","    os.makedirs(path)\n","\n","path_anytime = path + \"_anytime\"\n","if not os.path.isdir(path_anytime):\n","    os.makedirs(path_anytime)\n","\n","# UTILS\n","def create_cpnn():\n","    if not loss_on_seq:\n","        if not freeze_inputs_weights:\n","            return cPNN(column_class=model_class, device=device, seq_len=seq_len, train_verbose=False,\n","                        combination=combination, input_size=len(df.columns) - 2, hidden_size=hidden_size, output_size=2,\n","                        batch_size=batch_size)\n","        else:\n","            return cPNNExp(\n","                column_class=model_class,\n","                input_size=len(df.columns) - 2,\n","                hidden_size=hidden_size,\n","                output_size=2,\n","                batch_size=batch_size,\n","                device=device,\n","                seq_len=seq_len,\n","                train_verbose=False,\n","                combination=combination,\n","                remember_initial_states=rembember_initial_states,\n","            )\n","    return cPNNSeq(\n","        column_class=model_class,\n","        input_size=len(df.columns) - 2,\n","        hidden_size=hidden_size,\n","        output_size=2,\n","        batch_size=batch_size,\n","        device=device,\n","        seq_len=seq_len,\n","    )\n","\n","\n","# MAIN\n","if __name__ == \"__main__\":\n","    if args.model == \"cpnn\" and write_weights:\n","        try:\n","            df_test = pd.read_csv(os.path.join(\"datasets\", f\"{dataset}_test.csv\"))\n","        except:\n","            pass\n","    models = []\n","    params = []\n","    inputs = []\n","    hiddens = []\n","    print(dataset)\n","    for i in range(1, iterations + 1):\n","        models.append([])\n","        params.append([])\n","        inputs.append([])\n","        hiddens.append([])\n","        for k in perf_test:\n","            perf_test[k].append([])\n","        for k in perf_train:\n","            perf_train[k].append([])\n","        for k in perf_anytime:\n","            perf_anytime[k].append([])\n","        models[-1].append(create_cpnn())\n","        print(type(models[-1][-1].columns.columns[0]).__name__)\n","        print(f\"{i}/{iterations} iteration of {args.model}\")\n","        for task in range(1, df[\"task\"].max() + 1):\n","            params[-1].append([])\n","            inputs[-1].append([])\n","            hiddens[-1].append([])\n","            print(\"TASK:\", task)\n","            if task > 1:\n","                if args.model == \"cpnn\":\n","                    models[-1][-1].add_new_column()\n","                elif args.model == \"multiple\":\n","                    models[-1].append(create_cpnn())\n","                elif args.model == \"single\":\n","                    models[-1].append(pickle.loads(pickle.dumps(models[-1][-1])))\n","            df_task = df[df[\"task\"] == task]\n","            df_task = df_task.drop(columns=\"task\")\n","\n","            if pretraining_samples > 0:\n","                df_pre = df_task.iloc[:pretraining_samples, 0:]\n","                df_task = df_task.iloc[pretraining_samples:, 0:]\n","                perf_pretraining = models[-1][-1].pretraining(\n","                    df_pre.iloc[0:, :-1].values.astype(np.float32),\n","                    list(df_pre.iloc[0:, -1]),\n","                    pretraining_epochs,\n","                )\n","                with open(\n","                    os.path.join(path, \"pretraining.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(perf_pretraining, f)\n","\n","            for k in perf_test:\n","                perf_test[k][-1].append([])\n","            for k in perf_train:\n","                perf_train[k][-1].append([])\n","            for k in perf_anytime:\n","                perf_anytime[k][-1].append([])\n","            if len(df_task) % batch_size == 0:\n","                n_batches = int(len(df_task) / batch_size)\n","            else:\n","                n_batches = int(len(df_task) / batch_size) + 1\n","            for i in range(0, len(df_task), batch_size):\n","                x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","                y = list(df_task.iloc[i : i + batch_size, -1])\n","                print(int(i / batch_size) + 1, \"/\", n_batches, \" batch\", end=\"\\r\")\n","                if len(y) >= seq_len:\n","                    batch_perf_test, batch_perf_anytime, batch_perf_train = models[-1][-1].test_then_train(\n","                        x, y\n","                    )\n","                    for k in batch_perf_test:\n","                        perf_test[k][-1][-1].append(batch_perf_test[k])\n","                    for k in batch_perf_anytime:\n","                        perf_anytime[k][-1][-1].append(batch_perf_anytime[k])\n","                    for k in batch_perf_train:\n","                        perf_train[k][-1][-1].append(batch_perf_train[k])\n","                    if args.model == \"cpnn\" and write_weights:\n","                        try:\n","                            df_test_task = df_test[df_test[\"task\"] == task].drop(\n","                                columns=\"task\"\n","                            )\n","                            x_test = df_test_task.iloc[0:500, 0:-1].values.astype(\n","                                np.float32\n","                            )\n","                            inputs[-1][-1].append(\n","                                models[-1][-1]\n","                                .columns._convert_to_tensor_dataset(x_test)\n","                                .detach()\n","                                .numpy()\n","                            )\n","                            hiddens[-1][-1].append(models[-1][-1].get_hidden(x_test))\n","                        except:\n","                            pass\n","                        params[-1][-1].append(\n","                            pickle.loads(\n","                                pickle.dumps(\n","                                    models[-1][-1]\n","                                    .columns.columns[-1]\n","                                    .lstm.weight_ih_l0.data.detach()\n","                                    .numpy()\n","                                )\n","                            )\n","                        )\n","            print()\n","            print(\n","                f\"Accuracy media sul task {task}: {np.mean(perf_test['accuracy'][-1][-1])}\"\n","            )\n","            print()\n","\n","            with open(\n","                os.path.join(path, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_test, f)\n","\n","            with open(\n","                os.path.join(path_anytime, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_anytime, f)\n","\n","            with open(\n","                os.path.join(path, \"train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_train, f)\n","            with open(os.path.join(path, \"models.pkl\"), \"wb\") as f:\n","                pickle.dump(models, f)\n","\n","            if args.model == \"cpnn\" and write_weights:\n","                with open(\n","                    os.path.join(path, \"cpnn_params.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(params, f)\n","\n","                with open(\n","                    os.path.join(path, \"inputs.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(inputs, f)\n","\n","                with open(\n","                    os.path.join(path, \"hiddens.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(hiddens, f)\n","        print()"],"metadata":{"id":"AS1yflAoel29","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692007810892,"user_tz":-120,"elapsed":1088799,"user":{"displayName":"reza paki","userId":"01979157922216683878"}},"outputId":"396af997-3464-47bb-ec2a-231a98ce92ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sine_rw_10_1234\n","cLSTMLinear\n","1/1 iteration of cpnn\n","TASK: 1\n","\n","Accuracy media sul task 1: 0.967774936061381\n","\n","TASK: 2\n","\n","Accuracy media sul task 2: 0.8478021099744246\n","\n","TASK: 3\n","\n","Accuracy media sul task 3: 0.979215952685422\n","\n","TASK: 4\n","\n","Accuracy media sul task 4: 0.890772858056266\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6wktMApBZuzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","# MAIN\n","if __name__ == \"__main__\":\n","    if args.model == \"cpnn\" and write_weights:\n","        try:\n","            df_test = pd.read_csv(os.path.join(\"datasets\", f\"{dataset}_test.csv\"))\n","        except:\n","            pass\n","    models = []\n","    params = []\n","    inputs = []\n","    hiddens = []\n","    print(dataset)\n","    for i in range(1, iterations + 1):\n","        models.append([])\n","        params.append([])\n","        inputs.append([])\n","        hiddens.append([])\n","        for k in perf_test:\n","            perf_test[k].append([])\n","        for k in perf_train:\n","            perf_train[k].append([])\n","        for k in perf_anytime:\n","            perf_anytime[k].append([])\n","        models[-1].append(create_cpnn())\n","        print(type(models[-1][-1].columns.columns[0]).__name__)\n","        print(f\"{i}/{iterations} iteration of {args.model}\")\n","        for task in range(1, df[\"task\"].max() + 1):\n","            params[-1].append([])\n","            inputs[-1].append([])\n","            hiddens[-1].append([])\n","            print(\"TASK:\", task)\n","            if task > 1:\n","                if args.model == \"cpnn\":\n","                    models[-1][-1].add_new_column()\n","                elif args.model == \"multiple\":\n","                    models[-1].append(create_cpnn())\n","                elif args.model == \"single\":\n","                    models[-1].append(pickle.loads(pickle.dumps(models[-1][-1])))\n","            df_task = df[df[\"task\"] == task]\n","            df_task = df_task.drop(columns=\"task\")\n","\n","            if pretraining_samples > 0:\n","                df_pre = df_task.iloc[:pretraining_samples, 0:]\n","                df_task = df_task.iloc[pretraining_samples:, 0:]\n","                perf_pretraining = models[-1][-1].pretraining(\n","                    df_pre.iloc[0:, :-1].values.astype(np.float32),\n","                    list(df_pre.iloc[0:, -1]),\n","                    pretraining_epochs,\n","                )\n","                with open(\n","                    os.path.join(path, \"pretraining.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(perf_pretraining, f)\n","\n","            for k in perf_test:\n","                perf_test[k][-1].append([])\n","            for k in perf_train:\n","                perf_train[k][-1].append([])\n","            for k in perf_anytime:\n","                perf_anytime[k][-1].append([])\n","            if len(df_task) % batch_size == 0:\n","                n_batches = int(len(df_task) / batch_size)\n","            else:\n","                n_batches = int(len(df_task) / batch_size) + 1\n","            for i in range(0, len(df_task), batch_size):\n","                x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","                y = list(df_task.iloc[i : i + batch_size, -1])\n","                print(int(i / batch_size) + 1, \"/\", n_batches, \" batch\", end=\"\\r\")\n","                if len(y) >= seq_len:\n","                    batch_perf_test, batch_perf_anytime, batch_perf_train = models[-1][-1].test_then_train(\n","                        x, y\n","                    )\n","                    for k in batch_perf_test:\n","                        perf_test[k][-1][-1].append(batch_perf_test[k])\n","                    for k in batch_perf_anytime:\n","                        perf_anytime[k][-1][-1].append(batch_perf_anytime[k])\n","                    for k in batch_perf_train:\n","                        perf_train[k][-1][-1].append(batch_perf_train[k])\n","                    if args.model == \"cpnn\" and write_weights:\n","                        try:\n","                            df_test_task = df_test[df_test[\"task\"] == task].drop(\n","                                columns=\"task\"\n","                            )\n","                            x_test = df_test_task.iloc[0:500, 0:-1].values.astype(\n","                                np.float32\n","                            )\n","                            inputs[-1][-1].append(\n","                                models[-1][-1]\n","                                .columns._convert_to_tensor_dataset(x_test)\n","                                .detach()\n","                                .numpy()\n","                            )\n","                            hiddens[-1][-1].append(models[-1][-1].get_hidden(x_test))\n","                        except:\n","                            pass\n","                        params[-1][-1].append(\n","                            pickle.loads(\n","                                pickle.dumps(\n","                                    models[-1][-1]\n","                                    .columns.columns[-1]\n","                                    .lstm.weight_ih_l0.data.detach()\n","                                    .numpy()\n","                                )\n","                            )\n","                        )\n","            print()\n","            print(\n","                f\"Accuracy media sul task {task}: {np.mean(perf_test['accuracy'][-1][-1])}\"\n","            )\n","            print()\n","\n","            with open(\n","                os.path.join(path, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_test, f)\n","\n","            with open(\n","                os.path.join(path_anytime, \"test_then_train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_anytime, f)\n","\n","            with open(\n","                os.path.join(path, \"train.pkl\"),\n","                \"wb\",\n","            ) as f:\n","                pickle.dump(perf_train, f)\n","            with open(os.path.join(path, \"models.pkl\"), \"wb\") as f:\n","                pickle.dump(models, f)\n","\n","            if args.model == \"cpnn\" and write_weights:\n","                with open(\n","                    os.path.join(path, \"cpnn_params.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(params, f)\n","\n","                with open(\n","                    os.path.join(path, \"inputs.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(inputs, f)\n","\n","                with open(\n","                    os.path.join(path, \"hiddens.pkl\"),\n","                    \"wb\",\n","                ) as f:\n","                    pickle.dump(hiddens, f)\n","        print()"],"metadata":{"id":"-30MxWcOZQC7"},"execution_count":null,"outputs":[]}]}