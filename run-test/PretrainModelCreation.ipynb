{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","os.chdir('..')\n","sys.path.append(os.getcwd())"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gpYHkmOlsv9m"},"outputs":[],"source":["import torch\n","from utils.preprocess import *\n","\n","from Models.pretrain import *\n","from utils.utils import (\n","    cohen_kappa,\n","    get_samples_outputs,\n","    get_pred_from_outputs,\n",")\n","\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import argparse\n","from torch.autograd import Variable\n","import copy\n"]},{"cell_type":"markdown","metadata":{"id":"Q3SOVmoXDVKd"},"source":["# Weather datasets\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# TODO\n","dataset='Weather'\n","dataset_name = \"weather_pretraining\"\n","batch_size = 128\n","hidden_size = 250\n","seq_len = 11\n","iterations = 10\n","output_size = 2\n","num_layers = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","model_type = 'GRU' # or LSTM\n","if model_type == \"GRU\":\n","    model_class = GRU_Model\n","elif model_type == \"LSTM\":\n","    model_class = LSTM_Model\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RH</th>\n","      <th>T_d</th>\n","      <th>w_s</th>\n","      <th>w_d</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.878049</td>\n","      <td>0.180556</td>\n","      <td>0.142857</td>\n","      <td>-1.333083</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.878049</td>\n","      <td>0.138889</td>\n","      <td>0.571429</td>\n","      <td>0.652632</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.926829</td>\n","      <td>0.111111</td>\n","      <td>0.357143</td>\n","      <td>-1.298496</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.975610</td>\n","      <td>0.125000</td>\n","      <td>0.428571</td>\n","      <td>-0.875188</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.926829</td>\n","      <td>0.138889</td>\n","      <td>0.142857</td>\n","      <td>-1.347368</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24100</th>\n","      <td>-0.707317</td>\n","      <td>1.277778</td>\n","      <td>0.428571</td>\n","      <td>-1.346617</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24101</th>\n","      <td>0.560976</td>\n","      <td>2.138889</td>\n","      <td>0.714286</td>\n","      <td>-0.121053</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24102</th>\n","      <td>-0.073171</td>\n","      <td>2.041667</td>\n","      <td>-0.142857</td>\n","      <td>-0.309023</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24103</th>\n","      <td>-0.390244</td>\n","      <td>1.722222</td>\n","      <td>0.214286</td>\n","      <td>-0.128571</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24104</th>\n","      <td>-0.170732</td>\n","      <td>1.916667</td>\n","      <td>0.142857</td>\n","      <td>0.450376</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>24105 rows × 5 columns</p>\n","</div>"],"text/plain":["             RH       T_d       w_s       w_d  target\n","0     -0.878049  0.180556  0.142857 -1.333083       1\n","1     -0.878049  0.138889  0.571429  0.652632       1\n","2     -0.926829  0.111111  0.357143 -1.298496       1\n","3     -0.975610  0.125000  0.428571 -0.875188       1\n","4     -0.926829  0.138889  0.142857 -1.347368       1\n","...         ...       ...       ...       ...     ...\n","24100 -0.707317  1.277778  0.428571 -1.346617       1\n","24101  0.560976  2.138889  0.714286 -0.121053       1\n","24102 -0.073171  2.041667 -0.142857 -0.309023       1\n","24103 -0.390244  1.722222  0.214286 -0.128571       1\n","24104 -0.170732  1.916667  0.142857  0.450376       1\n","\n","[24105 rows x 5 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(f\"datasets/{dataset}/{dataset_name}.csv\")\n","df_task = df.drop('task', axis=1)\n","df_task"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493226,"status":"ok","timestamp":1710593991089,"user":{"displayName":"reza paki","userId":"01979157922216683878"},"user_tz":-60},"id":"9WzgTQq9vnif","outputId":"fcc7805b-6aa6-40c2-9ba7-65f6a8c0bdbc"},"outputs":[],"source":["for itter in range(1,iterations+1):\n","  Model = model_class(input_size=4,\n","        device=torch.device(\"cpu\"),\n","      \tnum_layers=num_layers,\n","        hidden_size=hidden_size,\n","        output_size=output_size,\n","        batch_size=batch_size,\n","          )\n","  Preprocess_object = Preprocess(seq_len=seq_len)\n","  with open(f\"Performance/Pretrain/{model_type}/{dataset}/Before/{dataset}-{model_type}-pretrain-hidden{hidden_size}-epoch10_itter{itter}.pickle\", \"wb\") as fp:\n","    pickle.dump(Model.state_dict(), fp)\n","\n","  if len(df_task) % batch_size == 0:\n","    n_batches = int(len(df_task) / batch_size)\n","  else:\n","    n_batches = int(len(df_task) / batch_size) + 1\n","  optimizer = torch.optim.Adam(Model.parameters(), lr=0.01)\n","  loss_fn = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n","  out_h = None\n","  for j in range(0,10):\n","    for i in range(0, len(df_task), batch_size):\n","      x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","      y = list(df_task.iloc[i : i + batch_size, -1])\n","      if len(y) >= seq_len:\n","        x = np.array(x)\n","        y = list(y)\n","        x, y, _ = Preprocess_object._load_batch(x, y)\n","        y_pred = Model(x)\n","        y_pred = get_samples_outputs(y_pred)\n","        pred, _ = get_pred_from_outputs(y_pred)\n","        loss = loss_fn(y_pred, y)\n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # update weights\n","        optimizer.step()\n","  with open(f\"Performance/Pretrain/{model_type}/{dataset}/After/{dataset}-{model_type}-pretrain-hidden{hidden_size}-epoch10_itter{itter}.pickle\", \"wb\") as fp:\n","    pickle.dump(Model.state_dict(), fp)\n","  print(f'itter {itter} finished')"]},{"cell_type":"markdown","metadata":{},"source":["# SINE datasets\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"j5MRnZ4-lZ-8"},"outputs":[],"source":["# TODO\n","dataset='SINE'\n","dataset_name = \"sine_rw10_mode5_extended_6-6_1234\"\n","Task_Number = 1\n","batch_size = 128\n","hidden_size = 250\n","seq_len = 10\n","iterations = 10\n","output_size = 2\n","num_layers = 1\n","loss_on_seq = False\n","freeze_inputs_weights = False\n","pretraining_samples = 0\n","pretraining_epochs = 0\n","write_weights = False\n","combination = False\n","model_type = 'GRU' # or LSTM\n","if model_type == \"GRU\":\n","    model_class = GRU_Model\n","elif model_type == \"LSTM\":\n","    model_class = LSTM_Model\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"AqcFv6Y8IzMk"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x1</th>\n","      <th>x2</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.718354</td>\n","      <td>0.957244</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.725173</td>\n","      <td>0.952800</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.772454</td>\n","      <td>0.922077</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.803595</td>\n","      <td>0.872254</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.148729</td>\n","      <td>0.872254</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>0.431281</td>\n","      <td>0.891558</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>0.391986</td>\n","      <td>0.877517</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>0.417829</td>\n","      <td>0.916618</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>0.115487</td>\n","      <td>0.916618</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>0.163136</td>\n","      <td>0.931397</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 3 columns</p>\n","</div>"],"text/plain":["             x1        x2  target\n","0      0.718354  0.957244       0\n","1      0.725173  0.952800       0\n","2      0.772454  0.922077       0\n","3      0.803595  0.872254       0\n","4      0.148729  0.872254       0\n","...         ...       ...     ...\n","49995  0.431281  0.891558       0\n","49996  0.391986  0.877517       0\n","49997  0.417829  0.916618       0\n","49998  0.115487  0.916618       0\n","49999  0.163136  0.931397       0\n","\n","[50000 rows x 3 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(f\"datasets/{dataset}/{dataset_name}.csv\")\n","df_task = df[df[\"task\"] == Task_Number]\n","df_task = df_task.drop('task', axis=1)\n","df_task"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for itter in range(1,iterations+1):\n","  Model = model_class(input_size=4,\n","        device=torch.device(\"cpu\"),\n","      \tnum_layers=num_layers,\n","        hidden_size=hidden_size,\n","        output_size=output_size,\n","        batch_size=batch_size,\n","          )\n","  Preprocess_object = Preprocess(seq_len=seq_len)\n","  with open(f\"Performance/Pretrain/{model_type}/{dataset}/Before/{dataset}-{model_type}-pretrain-hidden{hidden_size}-epoch10_itter{itter}.pickle\", \"wb\") as fp:\n","    pickle.dump(Model.state_dict(), fp)\n","\n","  if len(df_task) % batch_size == 0:\n","    n_batches = int(len(df_task) / batch_size)\n","  else:\n","    n_batches = int(len(df_task) / batch_size) + 1\n","  optimizer = torch.optim.Adam(Model.parameters(), lr=0.01)\n","  loss_fn = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n","  out_h = None\n","  for j in range(0,10):\n","    for i in range(0, len(df_task), batch_size):\n","      x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n","      y = list(df_task.iloc[i : i + batch_size, -1])\n","      if len(y) >= seq_len:\n","        x = np.array(x)\n","        y = list(y)\n","        x, y, _ = Preprocess_object._load_batch(x, y)\n","        y_pred = Model(x)\n","        y_pred = get_samples_outputs(y_pred)\n","        pred, _ = get_pred_from_outputs(y_pred)\n","        loss = loss_fn(y_pred, y)\n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # update weights\n","        optimizer.step()\n","  with open(f\"Performance/Pretrain/{model_type}/{dataset}/After/{dataset}-{model_type}-pretrain-hidden{hidden_size}-epoch10_itter{itter}.pickle\", \"wb\") as fp:\n","    pickle.dump(Model.state_dict(), fp)\n","  print(f'itter {itter} finished')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM82h1t6isZ5UsHdGaHl7jp","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}
