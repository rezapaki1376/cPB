{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gpYHkmOlsv9m"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.preprocess import *\n",
    "\n",
    "from Models.pretrain import *\n",
    "from utils.utils import (\n",
    "    cohen_kappa,\n",
    "    get_samples_outputs,\n",
    "    get_pred_from_outputs,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3SOVmoXDVKd"
   },
   "source": [
    "# Weather datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "dataset='Weather'\n",
    "dataset_name = \"weather_pretraining\"\n",
    "batch_size = 128\n",
    "hidden_size = 300\n",
    "seq_len = 11\n",
    "iterations = 10\n",
    "output_size = 2\n",
    "input_size = 4\n",
    "num_layers = 1\n",
    "loss_on_seq = False\n",
    "freeze_inputs_weights = False\n",
    "pretraining_samples = 0\n",
    "pretraining_epochs = 0\n",
    "write_weights = False\n",
    "combination = False\n",
    "model_type = 'GRU' # or LSTM\n",
    "if model_type == \"GRU\":\n",
    "    model_class = GRU_Model\n",
    "elif model_type == \"LSTM\":\n",
    "    model_class = LSTM_Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RH</th>\n",
       "      <th>T_d</th>\n",
       "      <th>w_s</th>\n",
       "      <th>w_d</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.878049</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-1.333083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.878049</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.926829</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>-1.298496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.975610</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.875188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.926829</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-1.347368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24100</th>\n",
       "      <td>-0.707317</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-1.346617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24101</th>\n",
       "      <td>0.560976</td>\n",
       "      <td>2.138889</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>-0.121053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24102</th>\n",
       "      <td>-0.073171</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.309023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24103</th>\n",
       "      <td>-0.390244</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.128571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24104</th>\n",
       "      <td>-0.170732</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.450376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             RH       T_d       w_s       w_d  target\n",
       "0     -0.878049  0.180556  0.142857 -1.333083       1\n",
       "1     -0.878049  0.138889  0.571429  0.652632       1\n",
       "2     -0.926829  0.111111  0.357143 -1.298496       1\n",
       "3     -0.975610  0.125000  0.428571 -0.875188       1\n",
       "4     -0.926829  0.138889  0.142857 -1.347368       1\n",
       "...         ...       ...       ...       ...     ...\n",
       "24100 -0.707317  1.277778  0.428571 -1.346617       1\n",
       "24101  0.560976  2.138889  0.714286 -0.121053       1\n",
       "24102 -0.073171  2.041667 -0.142857 -0.309023       1\n",
       "24103 -0.390244  1.722222  0.214286 -0.128571       1\n",
       "24104 -0.170732  1.916667  0.142857  0.450376       1\n",
       "\n",
       "[24105 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"datasets/{dataset}/{dataset_name}.csv\")\n",
    "df_task = df.drop('task', axis=1)\n",
    "df_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 493226,
     "status": "ok",
     "timestamp": 1710593991089,
     "user": {
      "displayName": "reza paki",
      "userId": "01979157922216683878"
     },
     "user_tz": -60
    },
    "id": "9WzgTQq9vnif",
    "outputId": "fcc7805b-6aa6-40c2-9ba7-65f6a8c0bdbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itter 1 finished\n",
      "itter 2 finished\n",
      "itter 3 finished\n",
      "itter 4 finished\n",
      "itter 5 finished\n",
      "itter 6 finished\n",
      "itter 7 finished\n",
      "itter 8 finished\n",
      "itter 9 finished\n",
      "itter 10 finished\n"
     ]
    }
   ],
   "source": [
    "for itter in range(1,iterations+1):\n",
    "  Model = model_class(input_size=input_size,\n",
    "        device=torch.device(\"cpu\"),\n",
    "      \tnum_layers=num_layers,\n",
    "        hidden_size=hidden_size,\n",
    "        output_size=output_size,\n",
    "        batch_size=batch_size,\n",
    "          )\n",
    "  Preprocess_object = Preprocess(seq_len=seq_len)\n",
    "  with open(f\"Performance/Pretrain/{model_type}/{dataset}/Before/{dataset}-{model_type}-pretrain-hidden{hidden_size}-epoch10_itter{itter}.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(Model.state_dict(), fp)\n",
    "\n",
    "  if len(df_task) % batch_size == 0:\n",
    "    n_batches = int(len(df_task) / batch_size)\n",
    "  else:\n",
    "    n_batches = int(len(df_task) / batch_size) + 1\n",
    "  optimizer = torch.optim.Adam(Model.parameters(), lr=0.01)\n",
    "  loss_fn = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "  out_h = None\n",
    "  for j in range(0,10):\n",
    "    for i in range(0, len(df_task), batch_size):\n",
    "      x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n",
    "      y = list(df_task.iloc[i : i + batch_size, -1])\n",
    "      if len(y) >= seq_len:\n",
    "        x = np.array(x)\n",
    "        y = list(y)\n",
    "        x, y, _ = Preprocess_object._load_batch(x, y)\n",
    "        y_pred, _ = Model(x)\n",
    "        y_pred = get_samples_outputs(y_pred)\n",
    "        pred, _ = get_pred_from_outputs(y_pred)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "  with open(f\"Performance/Pretrain/{model_type}/{dataset}/After/{dataset}-{model_type}-pretrain-hidden{hidden_size}-epoch10_itter{itter}.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(Model.state_dict(), fp)\n",
    "  print(f'itter {itter} finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINE datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "j5MRnZ4-lZ-8"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "dataset='SINE'\n",
    "dataset_name = \"sine_rw10_mode5_extended_6-6_1234\"\n",
    "Task_Number = 4\n",
    "batch_size = 128\n",
    "hidden_size = 300\n",
    "seq_len = 10\n",
    "iterations = 10\n",
    "output_size = 2\n",
    "input_size = 2\n",
    "num_layers = 1\n",
    "loss_on_seq = False\n",
    "freeze_inputs_weights = False\n",
    "pretraining_samples = 0\n",
    "pretraining_epochs = 0\n",
    "write_weights = False\n",
    "combination = False\n",
    "model_type = 'GRU' # or LSTM\n",
    "if model_type == \"GRU\":\n",
    "    model_class = GRU_Model\n",
    "elif model_type == \"LSTM\":\n",
    "    model_class = LSTM_Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "AqcFv6Y8IzMk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150000</th>\n",
       "      <td>0.913390</td>\n",
       "      <td>0.380142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150001</th>\n",
       "      <td>0.944662</td>\n",
       "      <td>0.337085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150002</th>\n",
       "      <td>0.897754</td>\n",
       "      <td>0.339643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150003</th>\n",
       "      <td>0.919343</td>\n",
       "      <td>0.291981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150004</th>\n",
       "      <td>0.951719</td>\n",
       "      <td>0.315031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.574179</td>\n",
       "      <td>0.117611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0.570672</td>\n",
       "      <td>0.159196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.608093</td>\n",
       "      <td>0.129590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0.605501</td>\n",
       "      <td>0.143455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0.569757</td>\n",
       "      <td>0.173520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x1        x2  target\n",
       "150000  0.913390  0.380142       1\n",
       "150001  0.944662  0.337085       1\n",
       "150002  0.897754  0.339643       1\n",
       "150003  0.919343  0.291981       1\n",
       "150004  0.951719  0.315031       1\n",
       "...          ...       ...     ...\n",
       "199995  0.574179  0.117611       0\n",
       "199996  0.570672  0.159196       0\n",
       "199997  0.608093  0.129590       0\n",
       "199998  0.605501  0.143455       0\n",
       "199999  0.569757  0.173520       0\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"datasets/{dataset}/{dataset_name}.csv\")\n",
    "df_task = df[df[\"task\"] == Task_Number]\n",
    "df_task = df_task.drop('task', axis=1)\n",
    "df_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itter 1 finished\n",
      "itter 2 finished\n",
      "itter 3 finished\n",
      "itter 4 finished\n",
      "itter 5 finished\n",
      "itter 6 finished\n",
      "itter 7 finished\n",
      "itter 8 finished\n",
      "itter 9 finished\n",
      "itter 10 finished\n"
     ]
    }
   ],
   "source": [
    "for itter in range(1,iterations+1):\n",
    "  Model = model_class(input_size=input_size,\n",
    "        device=torch.device(\"cpu\"),\n",
    "      \tnum_layers=num_layers,\n",
    "        hidden_size=hidden_size,\n",
    "        output_size=output_size,\n",
    "        batch_size=batch_size,\n",
    "          )\n",
    "  Preprocess_object = Preprocess(seq_len=seq_len)\n",
    "  with open(f\"Performance/Pretrain/{model_type}/{dataset}/Before/{dataset}-Task_{Task_Number}-{model_type}-pretrain-hidden{hidden_size}-epoch10_iter{itter}.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(Model.state_dict(), fp)\n",
    "\n",
    "  if len(df_task) % batch_size == 0:\n",
    "    n_batches = int(len(df_task) / batch_size)\n",
    "  else:\n",
    "    n_batches = int(len(df_task) / batch_size) + 1\n",
    "  optimizer = torch.optim.Adam(Model.parameters(), lr=0.01)\n",
    "  loss_fn = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "  out_h = None\n",
    "  for j in range(0,10):\n",
    "    for i in range(0, len(df_task), batch_size):\n",
    "      x = df_task.iloc[i : i + batch_size, 0:-1].values.astype(np.float32)\n",
    "      y = list(df_task.iloc[i : i + batch_size, -1])\n",
    "      if len(y) >= seq_len:\n",
    "        x = np.array(x)\n",
    "        y = list(y)\n",
    "        x, y, _ = Preprocess_object._load_batch(x, y)\n",
    "        y_pred, _ = Model(x)\n",
    "        y_pred = get_samples_outputs(y_pred)\n",
    "        pred, _ = get_pred_from_outputs(y_pred)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "  with open(f\"Performance/Pretrain/{model_type}/{dataset}/After/{dataset}-Task_{Task_Number}-{model_type}-pretrain-hidden{hidden_size}-epoch10_iter{itter}.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(Model.state_dict(), fp)\n",
    "  print(f'itter {itter} finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM82h1t6isZ5UsHdGaHl7jp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CPB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
