{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Models.pretrain import *\n",
    "from Models.cPB import cPB\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import pprint\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='torch.storage')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch.storage')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='torch.storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(number, digits) -> float:\n",
    "    stepper = 10.0 ** digits\n",
    "    return np.trunc(stepper * number) / stepper\n",
    "\n",
    "def print_stats(data_list, label):\n",
    "    mean_val = np.mean(data_list)\n",
    "    std_val = np.std(data_list)\n",
    "\n",
    "    # Truncate values instead of rounding\n",
    "    truncated_mean = truncate(mean_val, 3)\n",
    "    truncated_std = truncate(std_val, 3)\n",
    "    print(f\"{label} Mean: {truncated_mean}%\")\n",
    "    print(f\"{label} Std:  {truncated_std}%\")\n",
    "    print(f\"{label} complete vale:  {truncated_mean}+{truncated_std}\")\n",
    "    print(10 * '*')\n",
    "    \n",
    "def replication(data1):\n",
    "  kappa = data1\n",
    "\n",
    "  # Apply the filtering\n",
    "  before_50 = kappa[:50]  # Elements up to index 50 (exclusive)\n",
    "  after_50 = kappa[50:]\n",
    "  after_50_filtered = after_50[::2]\n",
    "  filtered_kappa = np.concatenate((before_50, after_50_filtered))\n",
    "  return filtered_kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'GRU'\n",
    "batch_size = 128\n",
    "hidden_size = 50\n",
    "seq_len = 10\n",
    "epoch_size=10\n",
    "lr = 0.01\n",
    "number_of_tasks=4\n",
    "mask_selection_NofBatch = 50\n",
    "input_size=2\n",
    "iteration=1\n",
    "mask_init='uniform'\n",
    "dataset='SINE'\n",
    "dataset_name = \"sine_rw10_mode5_extended_16-16_1234\"\n",
    "Pretrain_task = '1'\n",
    "df = pd.read_csv(os.path.join(f\"datasets/{dataset}/\", f\"{dataset_name}.csv\"))\n",
    "pretrain_model_addr=f'Performance/Pretrain/{base_model}/{dataset}/After/{dataset}-Task_{Pretrain_task}-{base_model}-pretrain-hidden{hidden_size}-epoch10_iter{iteration}.pickle'\n",
    "mask_weights=[] #if we have initial masks then reload it here\n",
    "\n",
    "\n",
    "mask_option = 'SUM'\n",
    "model_type = 'cPB'\n",
    "batch_first = True\n",
    "low_rank = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'GRU'\n",
    "batch_size = 128\n",
    "hidden_size = 50\n",
    "seq_len = 11\n",
    "epoch_size=10\n",
    "lr = 0.01\n",
    "number_of_tasks=4\n",
    "mask_selection_NofBatch = 50\n",
    "input_size=4\n",
    "mask_init='uniform'\n",
    "dataset='Weather'\n",
    "dataset_name = \"weather_st124_1conf\"\n",
    "Pretrain_task = '1'\n",
    "mask_option = 'SUM'\n",
    "model_type = 'cPB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50-1 Mean: 0.636%\n",
      "Batch 50-1 Std:  0.01%\n",
      "Batch 50-1 complete vale:  0.636+0.01\n",
      "**********\n",
      "End 1 Mean: 0.663%\n",
      "End 1 Std:  0.007%\n",
      "End 1 complete vale:  0.663+0.007\n",
      "**********\n",
      "Batch 50-2 Mean: 0.702%\n",
      "Batch 50-2 Std:  0.01%\n",
      "Batch 50-2 complete vale:  0.702+0.01\n",
      "**********\n",
      "End 2 Mean: 0.735%\n",
      "End 2 Std:  0.006%\n",
      "End 2 complete vale:  0.735+0.006\n",
      "**********\n",
      "Batch 50-3 Mean: 0.392%\n",
      "Batch 50-3 Std:  0.019%\n",
      "Batch 50-3 complete vale:  0.392+0.019\n",
      "**********\n",
      "End 3 Mean: 0.567%\n",
      "End 3 Std:  0.026%\n",
      "End 3 complete vale:  0.567+0.026\n",
      "**********\n",
      "Batch 50-4 Mean: 0.734%\n",
      "Batch 50-4 Std:  0.021%\n",
      "Batch 50-4 complete vale:  0.734+0.021\n",
      "**********\n",
      "End 4 Mean: 0.751%\n",
      "End 4 Std:  0.014%\n",
      "End 4 complete vale:  0.751+0.014\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "batch_50_1_1 = []\n",
    "batch_50_2_1 = []\n",
    "batch_50_3_1 = []\n",
    "batch_50_4_1 = []\n",
    "end_1_1 = []\n",
    "end_2_1 = []\n",
    "end_3_1 = []\n",
    "end_4_1 = []\n",
    "\n",
    "all_results_2 = [[] for i in range(0,8)]\n",
    "for i in range (1,11):\n",
    "  file_1 = f'Performance/Results/{model_type}/{dataset}/Periodic/pretrain_T{Pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}-iter{i}.pkl'\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_2[0].append(np.mean(data1['task_1']['kappa'][0:50]))\n",
    "  out = replication(data1['task_1']['kappa'][:])\n",
    "  all_results_2[1].append(np.mean(out))\n",
    "  all_results_2[2].append(np.mean(data1['task_2']['kappa'][0:50]))\n",
    "  out = replication(data1['task_2']['kappa'][:])\n",
    "  all_results_2[3].append(np.mean(out))\n",
    "  all_results_2[4].append(np.mean(data1['task_3']['kappa'][0:50]))\n",
    "  out = replication(data1['task_3']['kappa'][:])\n",
    "  all_results_2[5].append(np.mean(out))\n",
    "  all_results_2[6].append(np.mean(data1['task_4']['kappa'][0:50]))\n",
    "  out = replication(data1['task_4']['kappa'][:])\n",
    "  all_results_2[7].append(np.mean(out))\n",
    "\n",
    "\n",
    "print_stats(all_results_2[0], \"Batch 50-1\")\n",
    "print_stats(all_results_2[1], \"End 1\")\n",
    "print_stats(all_results_2[2], \"Batch 50-2\")\n",
    "print_stats(all_results_2[3], \"End 2\")\n",
    "print_stats(all_results_2[4], \"Batch 50-3\")\n",
    "print_stats(all_results_2[5], \"End 3\")\n",
    "print_stats(all_results_2[6], \"Batch 50-4\")\n",
    "print_stats(all_results_2[7], \"End 4\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM82h1t6isZ5UsHdGaHl7jp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CPB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
