{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Models.pretrain import *\n",
    "from Models.cPB import cPB\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import pprint\n",
    "import copy\n",
    "import warnings\n",
    "from scipy.stats import shapiro,ttest_ind,wilcoxon\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='torch.storage')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch.storage')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='torch.storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(number, digits) -> float:\n",
    "    stepper = 10.0 ** digits\n",
    "    return np.trunc(stepper * number) / stepper\n",
    "\n",
    "def print_stats(data_list, label):\n",
    "    mean_val = np.mean(data_list)\n",
    "    std_val = np.std(data_list)\n",
    "\n",
    "    # Truncate values instead of rounding\n",
    "    truncated_mean = truncate(mean_val, 2)\n",
    "    truncated_std = truncate(std_val, 2)\n",
    "    print(f\"{label} Mean: {truncated_mean}%\")\n",
    "    print(f\"{label} Std:  {truncated_std}%\")\n",
    "    print(f\"{label} complete vale:  {truncated_mean} ± {truncated_std}\")\n",
    "    print(10 * '*')\n",
    "    return truncated_mean, truncated_std\n",
    "    \n",
    "def replication(data1):\n",
    "  kappa = data1\n",
    "\n",
    "  # Apply the filtering\n",
    "  before_50 = kappa[:50]  # Elements up to index 50 (exclusive)\n",
    "  after_50 = kappa[50:]\n",
    "  after_50_filtered = after_50[::2]\n",
    "  filtered_kappa = np.concatenate((before_50, after_50_filtered))\n",
    "  return filtered_kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anytime scenario\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'GRU'\n",
    "hidden_size = 50\n",
    "dataset = 'SINE'\n",
    "dataset_name = \"sine_rw10_mode5_extended_16-16_1234\"\n",
    "mask_option = 'SUM'\n",
    "model_type = 'cPB'\n",
    "pretrain_task = '2'\n",
    "batch_50_1 = []\n",
    "batch_50_2 = []\n",
    "batch_50_3 = []\n",
    "batch_50_4 = []\n",
    "end_1 = []\n",
    "end_2 = []\n",
    "end_3 = []\n",
    "end_4 = []\n",
    "\n",
    "all_results_1 = [[] for i in range(0,8)]\n",
    "\n",
    "for i in range (1,11):\n",
    "  file_1  = f'Performance/Results/{model_type}/{dataset}/Anytime2/pretrain-T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}_iter{i}.pkl'\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_1[0].append(data1['task_1']['kappa'][50*128-1])\n",
    "  all_results_1[1].append(data1['task_1']['kappa'][-1])\n",
    "  all_results_1[2].append(data1['task_2']['kappa'][50*128-1])\n",
    "  all_results_1[3].append(data1['task_2']['kappa'][-1])\n",
    "  all_results_1[4].append(data1['task_3']['kappa'][50*128-1])\n",
    "  all_results_1[5].append(data1['task_3']['kappa'][-1])\n",
    "  all_results_1[6].append(data1['task_4']['kappa'][50*128-1])\n",
    "  all_results_1[7].append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "  batch_50_1.append(data1['task_1']['kappa'][50*128-1])\n",
    "  batch_50_2.append(data1['task_2']['kappa'][50*128-1])\n",
    "  batch_50_3.append(data1['task_3']['kappa'][50*128-1])\n",
    "  batch_50_4.append(data1['task_4']['kappa'][50*128-1])\n",
    "  end_1.append(data1['task_1']['kappa'][-1])\n",
    "  end_2.append(data1['task_2']['kappa'][-1])\n",
    "  end_3.append(data1['task_3']['kappa'][-1])\n",
    "  end_4.append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(batch_50_1, \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_1, \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_2, \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_2, \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_3, \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_3, \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_4, \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_4, \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'GRU'\n",
    "hidden_size = 50\n",
    "dataset = 'SINE'\n",
    "dataset_name = \"sine_rw10_mode5_extended_16-16_2341\"\n",
    "model_type = 'cGRU'\n",
    "pretrain_task = '2'\n",
    "\n",
    "batch_50_1 = []\n",
    "batch_50_2 = []\n",
    "batch_50_3 = []\n",
    "batch_50_4 = []\n",
    "end_1 = []\n",
    "end_2 = []\n",
    "end_3 = []\n",
    "end_4 = []\n",
    "\n",
    "all_results_2 = [[] for i in range(0,8)]\n",
    "\n",
    "for i in range (1,11):\n",
    "  file_1  = f'Performance/Results/{model_type}/Anytime/{dataset}/pretrain_T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-iter{i}_periodic.pkl'\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_2[0].append(data1['task_1']['kappa'][50*128-1])\n",
    "  all_results_2[1].append(data1['task_1']['kappa'][-1])\n",
    "  all_results_2[2].append(data1['task_2']['kappa'][50*128-1])\n",
    "  all_results_2[3].append(data1['task_2']['kappa'][-1])\n",
    "  all_results_2[4].append(data1['task_3']['kappa'][50*128-1])\n",
    "  all_results_2[5].append(data1['task_3']['kappa'][-1])\n",
    "  all_results_2[6].append(data1['task_4']['kappa'][50*128-1])\n",
    "  all_results_2[7].append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "  batch_50_1.append(data1['task_1']['kappa'][50*128-1])\n",
    "  batch_50_2.append(data1['task_2']['kappa'][50*128-1])\n",
    "  batch_50_3.append(data1['task_3']['kappa'][50*128-1])\n",
    "  batch_50_4.append(data1['task_4']['kappa'][50*128-1])\n",
    "  end_1.append(data1['task_1']['kappa'][-1])\n",
    "  end_2.append(data1['task_2']['kappa'][-1])\n",
    "  end_3.append(data1['task_3']['kappa'][-1])\n",
    "  end_4.append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(batch_50_1, \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_1, \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_2, \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_2, \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_3, \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_3, \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_4, \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_4, \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "  A = all_results_1[i]\n",
    "  B = all_results_2[i]\n",
    "  stat_A, p_value_A = shapiro(A)\n",
    "  stat_B, p_value_B = shapiro(B)\n",
    "  if p_value_A >= 0.05 and p_value_B >= 0.05:\n",
    "    print('Both are normal distribution')\n",
    "    t_stat, p_ttest = ttest_ind(A, B, equal_var=False, alternative='greater')\n",
    "    if p_ttest < 0.05:\n",
    "      print('*****The mean of A is significantly greater Than B')\n",
    "    else:\n",
    "      print('*****The mean of B is significantly greater Than A')\n",
    "\n",
    "  else:\n",
    "    if p_value_A < 0.05 and p_value_B < 0.05:\n",
    "      print('neither A or B is normally distributed')\n",
    "    elif p_value_A < 0.05:\n",
    "      print('B is normally distributed')\n",
    "    elif p_value_B < 0.05:\n",
    "      print('A is normally distributed')\n",
    "    stat_wilcox, p_wilcox = wilcoxon(A, B, alternative='greater')\n",
    "    if p_wilcox < 0.05:\n",
    "      print('*****The mean of A is significantly greater Than B')\n",
    "    else:\n",
    "      print('*****The mean of B is significantly greater Than A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'GRU'\n",
    "hidden_size = 50\n",
    "dataset = 'Weather'\n",
    "dataset_name = \"weather_st124_1conf\"\n",
    "mask_option = 'DOT'\n",
    "model_type = 'cPB'\n",
    "pretrain_task = '2'\n",
    "batch_50_1 = []\n",
    "batch_50_2 = []\n",
    "batch_50_3 = []\n",
    "batch_50_4 = []\n",
    "end_1 = []\n",
    "end_2 = []\n",
    "end_3 = []\n",
    "end_4 = []\n",
    "\n",
    "all_results_2 = [[] for i in range(0,8)]\n",
    "\n",
    "for i in range (1,11):\n",
    "  file_1  = f'Performance/Results/{model_type}/{dataset}/Anytime2/pretrain-T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}_iter{i}.pkl'\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_2[0].append(data1['task_1']['kappa'][50*128-1])\n",
    "  all_results_2[1].append(data1['task_1']['kappa'][-1])\n",
    "  all_results_2[2].append(data1['task_2']['kappa'][50*128-1])\n",
    "  all_results_2[3].append(data1['task_2']['kappa'][-1])\n",
    "  all_results_2[4].append(data1['task_3']['kappa'][50*128-1])\n",
    "  all_results_2[5].append(data1['task_3']['kappa'][-1])\n",
    "  all_results_2[6].append(data1['task_4']['kappa'][50*128-1])\n",
    "  all_results_2[7].append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "  batch_50_1.append(data1['task_1']['kappa'][50*128-1])\n",
    "  batch_50_2.append(data1['task_2']['kappa'][50*128-1])\n",
    "  batch_50_3.append(data1['task_3']['kappa'][50*128-1])\n",
    "  batch_50_4.append(data1['task_4']['kappa'][50*128-1])\n",
    "  end_1.append(data1['task_1']['kappa'][-1])\n",
    "  end_2.append(data1['task_2']['kappa'][-1])\n",
    "  end_3.append(data1['task_3']['kappa'][-1])\n",
    "  end_4.append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(batch_50_1, \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_1, \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_2, \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_2, \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_3, \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_3, \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_4, \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_4, \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'GRU'\n",
    "hidden_size = 50\n",
    "dataset = 'Weather'\n",
    "dataset_name = \"weather_st124_4conf\"\n",
    "model_type = 'cGRU'\n",
    "pretrain_task = '1'\n",
    "\n",
    "batch_50_1 = []\n",
    "batch_50_2 = []\n",
    "batch_50_3 = []\n",
    "batch_50_4 = []\n",
    "end_1 = []\n",
    "end_2 = []\n",
    "end_3 = []\n",
    "end_4 = []\n",
    "\n",
    "all_results_2 = [[] for i in range(0,8)]\n",
    "\n",
    "for i in range (1,11):\n",
    "  file_1  = f'Performance/Results/{model_type}/Anytime/{dataset}/pretrain_T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-iter{i}_periodic.pkl'\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_2[0].append(data1['task_1']['kappa'][50*128-1])\n",
    "  all_results_2[1].append(data1['task_1']['kappa'][-1])\n",
    "  all_results_2[2].append(data1['task_2']['kappa'][50*128-1])\n",
    "  all_results_2[3].append(data1['task_2']['kappa'][-1])\n",
    "  all_results_2[4].append(data1['task_3']['kappa'][50*128-1])\n",
    "  all_results_2[5].append(data1['task_3']['kappa'][-1])\n",
    "  all_results_2[6].append(data1['task_4']['kappa'][50*128-1])\n",
    "  all_results_2[7].append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "  batch_50_1.append(data1['task_1']['kappa'][50*128-1])\n",
    "  batch_50_2.append(data1['task_2']['kappa'][50*128-1])\n",
    "  batch_50_3.append(data1['task_3']['kappa'][50*128-1])\n",
    "  batch_50_4.append(data1['task_4']['kappa'][50*128-1])\n",
    "  end_1.append(data1['task_1']['kappa'][-1])\n",
    "  end_2.append(data1['task_2']['kappa'][-1])\n",
    "  end_3.append(data1['task_3']['kappa'][-1])\n",
    "  end_4.append(data1['task_4']['kappa'][-1])\n",
    "\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(batch_50_1, \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_1, \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_2, \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_2, \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_3, \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_3, \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(batch_50_4, \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(end_4, \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "base_model = 'GRU'\n",
    "hidden_size = 250\n",
    "dataset = 'SINE'\n",
    "dataset_name = \"sine_rw10_mode5_extended_16-16_2341\"\n",
    "mask_option = 'SUM'  # Fixed mask_option\n",
    "model_type = 'cPB'\n",
    "pretrain_task = '4'\n",
    "\n",
    "all_results_1 = [[] for i in range(0,8)]\n",
    "for i in range (1,11):\n",
    "  file_1  = f'Performance/Results/{model_type}/{dataset}/Periodic/pretrain-T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}_iter{i}.pkl'\n",
    "\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_1[0].append(np.mean(data1['task_1']['kappa'][0:50]))\n",
    "  all_results_1[1].append(np.mean(data1['task_1']['kappa'][:]))\n",
    "  all_results_1[2].append(np.mean(data1['task_2']['kappa'][0:50]))\n",
    "  all_results_1[3].append(np.mean(data1['task_2']['kappa'][:]))\n",
    "  all_results_1[4].append(np.mean(data1['task_3']['kappa'][0:50]))\n",
    "  all_results_1[5].append(np.mean(data1['task_3']['kappa'][:]))\n",
    "  all_results_1[6].append(np.mean(data1['task_4']['kappa'][0:50]))\n",
    "  all_results_1[7].append(np.mean(data1['task_4']['kappa'][:]))\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(all_results_1[0], \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[1], \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[2], \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[3], \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[4], \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[5], \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[6], \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[7], \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\\T\\B \")\n",
    "\n",
    "\n",
    "print(np.round(np.mean(all_results_1[0]),3),',',np.round(np.mean(all_results_1[1]),3),',',np.round(np.mean(all_results_1[2]),3),',',np.round(np.mean(all_results_1[3]),3),',',np.round(np.mean(all_results_1[4]),3),',',np.round(np.mean(all_results_1[5]),3),',',np.round(np.mean(all_results_1[6]),3),',',np.round(np.mean(all_results_1[7]),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "base_model = 'GRU'\n",
    "hidden_size = 250\n",
    "dataset = 'SINE'\n",
    "dataset_name = \"sine_rw10_mode5_extended_16-16_2341\"\n",
    "model_type = 'cGRU'\n",
    "pretrain_task = '1'\n",
    "\n",
    "\n",
    "batch_50_1_1 = []\n",
    "batch_50_2_1 = []\n",
    "batch_50_3_1 = []\n",
    "batch_50_4_1 = []\n",
    "end_1_1 = []\n",
    "end_2_1 = []\n",
    "end_3_1 = []\n",
    "end_4_1 = []\n",
    "\n",
    "all_results_2 = [[] for i in range(0,8)]\n",
    "for i in range (1,11):\n",
    "  file_1  = f'Performance/Results/{model_type}/Periodic/{dataset}/pretrain_T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-iter{i}_periodic.pkl'\n",
    "\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_2[0].append(np.mean(data1['task_1']['kappa'][0:50]))\n",
    "  all_results_2[1].append(np.mean(data1['task_1']['kappa'][:]))\n",
    "  all_results_2[2].append(np.mean(data1['task_2']['kappa'][0:50]))\n",
    "  all_results_2[3].append(np.mean(data1['task_2']['kappa'][:]))\n",
    "  all_results_2[4].append(np.mean(data1['task_3']['kappa'][0:50]))\n",
    "  all_results_2[5].append(np.mean(data1['task_3']['kappa'][:]))\n",
    "  all_results_2[6].append(np.mean(data1['task_4']['kappa'][0:50]))\n",
    "  all_results_2[7].append(np.mean(data1['task_4']['kappa'][:]))\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(all_results_2[0], \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[1], \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[2], \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[3], \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[4], \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[5], \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[6], \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[7], \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\\T\\B \")\n",
    "\n",
    "\n",
    "print(np.round(np.mean(all_results_2[0]),3),',',np.round(np.mean(all_results_2[1]),3),',',np.round(np.mean(all_results_2[2]),3),',',np.round(np.mean(all_results_2[3]),3),',',np.round(np.mean(all_results_2[4]),3),',',np.round(np.mean(all_results_2[5]),3),',',np.round(np.mean(all_results_2[6]),3),',',np.round(np.mean(all_results_2[7]),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "  A = all_results_1[i]\n",
    "  B = all_results_2[i]\n",
    "  stat_A, p_value_A = shapiro(A)\n",
    "  stat_B, p_value_B = shapiro(B)\n",
    "  if p_value_A >= 0.05 and p_value_B >= 0.05:\n",
    "    print('Both are normal distribution')\n",
    "    t_stat, p_ttest = ttest_ind(A, B, equal_var=False, alternative='greater')\n",
    "    if p_ttest < 0.05:\n",
    "      print('*****The mean of A is significantly greater Than B')\n",
    "    else:\n",
    "      print('*****The mean of B is significantly greater Than A')\n",
    "\n",
    "  else:\n",
    "    if p_value_A < 0.05 and p_value_B < 0.05:\n",
    "      print('neither A or B is normally distributed')\n",
    "    elif p_value_A < 0.05:\n",
    "      print('B is normally distributed')\n",
    "    elif p_value_B < 0.05:\n",
    "      print('A is normally distributed')\n",
    "    stat_wilcox, p_wilcox = wilcoxon(A, B, alternative='greater')\n",
    "    if p_wilcox < 0.05:\n",
    "      print('*****The mean of A is significantly greater Than B')\n",
    "    else:\n",
    "      print('*****The mean of B is significantly greater Than A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "base_model = 'GRU'\n",
    "hidden_size = 250\n",
    "dataset = 'Weather'\n",
    "dataset_name = \"weather_st124_3conf\"\n",
    "model_type = 'cGRU'\n",
    "pretrain_task = '1'\n",
    "\n",
    "\n",
    "batch_50_1_1 = []\n",
    "batch_50_2_1 = []\n",
    "batch_50_3_1 = []\n",
    "batch_50_4_1 = []\n",
    "end_1_1 = []\n",
    "end_2_1 = []\n",
    "end_3_1 = []\n",
    "end_4_1 = []\n",
    "\n",
    "all_results_2 = [[] for i in range(0,8)]\n",
    "for i in range (1,11):\n",
    "  file_1  = f'Performance/Results/{model_type}/Periodic/{dataset}/pretrain_T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-iter{i}_periodic.pkl'\n",
    "\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_2[0].append(np.mean(data1['task_1']['kappa'][0:50]))\n",
    "  all_results_2[1].append(np.mean(data1['task_1']['kappa'][:]))\n",
    "  all_results_2[2].append(np.mean(data1['task_2']['kappa'][0:50]))\n",
    "  all_results_2[3].append(np.mean(data1['task_2']['kappa'][:]))\n",
    "  all_results_2[4].append(np.mean(data1['task_3']['kappa'][0:50]))\n",
    "  all_results_2[5].append(np.mean(data1['task_3']['kappa'][:]))\n",
    "  all_results_2[6].append(np.mean(data1['task_4']['kappa'][0:50]))\n",
    "  all_results_2[7].append(np.mean(data1['task_4']['kappa'][:]))\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(all_results_2[0], \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[1], \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[2], \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[3], \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[4], \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[5], \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[6], \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_2[7], \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\\T\\B \")\n",
    "\n",
    "\n",
    "print(np.round(np.mean(all_results_2[0]),3),',',np.round(np.mean(all_results_2[1]),3),',',np.round(np.mean(all_results_2[2]),3),',',np.round(np.mean(all_results_2[3]),3),',',np.round(np.mean(all_results_2[4]),3),',',np.round(np.mean(all_results_2[5]),3),',',np.round(np.mean(all_results_2[6]),3),',',np.round(np.mean(all_results_2[7]),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "base_model = 'GRU'\n",
    "hidden_size = 50\n",
    "dataset = 'Weather'\n",
    "dataset_name = \"weather_st124_3conf\"\n",
    "mask_option = 'SUM'  # Fixed mask_option\n",
    "model_type = 'cPB'\n",
    "pretrain_task = '1'\n",
    "\n",
    "\n",
    "batch_50_1_1 = []\n",
    "batch_50_2_1 = []\n",
    "batch_50_3_1 = []\n",
    "batch_50_4_1 = []\n",
    "end_1_1 = []\n",
    "end_2_1 = []\n",
    "end_3_1 = []\n",
    "end_4_1 = []\n",
    "\n",
    "all_results_1 = [[] for i in range(0,8)]\n",
    "for i in range (1,11):\n",
    "  # file_1 = f'Performance/Results/{model_type}/{dataset}/Periodic/pretrain_T{Pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}-iter{i}.pkl'\n",
    "  file_1  = f'Performance/Results/{model_type}/{dataset}/Periodic/pretrain_T{pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}-iter{i}.pkl'\n",
    "\n",
    "  with open(file_1, 'rb') as f:\n",
    "    data1 = pickle.load(f)\n",
    "\n",
    "  all_results_1[0].append(np.mean(data1['task_1']['kappa'][0:50]))\n",
    "  all_results_1[1].append(np.mean(data1['task_1']['kappa'][:]))\n",
    "  all_results_1[2].append(np.mean(data1['task_2']['kappa'][0:50]))\n",
    "  all_results_1[3].append(np.mean(data1['task_2']['kappa'][:]))\n",
    "  all_results_1[4].append(np.mean(data1['task_3']['kappa'][0:50]))\n",
    "  all_results_1[5].append(np.mean(data1['task_3']['kappa'][:]))\n",
    "  all_results_1[6].append(np.mean(data1['task_4']['kappa'][0:50]))\n",
    "  all_results_1[7].append(np.mean(data1['task_4']['kappa'][:]))\n",
    "\n",
    "Mean_list = []\n",
    "var_list = []\n",
    "Mean,Var = print_stats(all_results_1[0], \"Batch 50-1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[1], \"End 1\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[2], \"Batch 50-2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[3], \"End 2\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[4], \"Batch 50-3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[5], \"End 3\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[6], \"Batch 50-4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "Mean,Var = print_stats(all_results_1[7], \"End 4\")\n",
    "Mean_list.append(Mean)\n",
    "var_list.append(Var)\n",
    "\n",
    "print(f\"&{Mean_list[0]} ± {var_list[0]}& {Mean_list[1]} ± {var_list[1]}& {Mean_list[2]} ± {var_list[2]}& {Mean_list[3]} ± {var_list[3]}& {Mean_list[4]} ± {var_list[4]}& {Mean_list[5]} ± {var_list[5]}& {Mean_list[6]} ± {var_list[6]}& {Mean_list[7]} ± {var_list[7]}\")\n",
    "\n",
    "\n",
    "print(np.round(np.mean(all_results_1[0]),3),',',np.round(np.mean(all_results_1[1]),3),',',np.round(np.mean(all_results_1[2]),3),',',np.round(np.mean(all_results_1[3]),3),',',np.round(np.mean(all_results_1[4]),3),',',np.round(np.mean(all_results_1[5]),3),',',np.round(np.mean(all_results_1[6]),3),',',np.round(np.mean(all_results_1[7]),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "  A = all_results_1[i]\n",
    "  B = all_results_2[i]\n",
    "  stat_A, p_value_A = shapiro(A)\n",
    "  stat_B, p_value_B = shapiro(B)\n",
    "  if p_value_A >= 0.05 and p_value_B >= 0.05:\n",
    "    print('Both are normal distribution')\n",
    "    t_stat, p_ttest = ttest_ind(A, B, equal_var=False, alternative='greater')\n",
    "    if p_ttest < 0.05:\n",
    "      print('*****The mean of A is significantly greater Than B')\n",
    "    else:\n",
    "      print('*****The mean of B is significantly greater Than A')\n",
    "\n",
    "  else:\n",
    "    if p_value_A < 0.05 and p_value_B < 0.05:\n",
    "      print('neither A or B is normally distributed')\n",
    "    elif p_value_A < 0.05:\n",
    "      print('B is normally distributed')\n",
    "    elif p_value_B < 0.05:\n",
    "      print('A is normally distributed')\n",
    "    stat_wilcox, p_wilcox = wilcoxon(A, B, alternative='greater')\n",
    "    if p_wilcox < 0.05:\n",
    "      print('*****The mean of A is significantly greater Than B')\n",
    "    else:\n",
    "      print('*****The mean of B is significantly greater Than A')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM82h1t6isZ5UsHdGaHl7jp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CPB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
