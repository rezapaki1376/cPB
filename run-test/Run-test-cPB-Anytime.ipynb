{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Models.pretrain import *\n",
    "from Models.cPB import *\n",
    "from river import stream\n",
    "from evaluation.cl_evaluation import EvaluateContinualLearning\n",
    "from evaluation.learner_config import LearnerConfig\n",
    "from evaluation.prequential_evaluation import EvaluatePrequential, make_dir\n",
    "import traceback\n",
    "from evaluation.test_utils import *\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import pprint\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='torch.storage')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch.storage')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='torch.storage')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size_list = [50]\n",
    "pretrain_mask_list = ['2']\n",
    "for hidden in hidden_size_list:\n",
    "  for pretrain in pretrain_mask_list:\n",
    "    for iter in range(1,11):\n",
    "      ###### Config the parameters ######\n",
    "      base_model = 'GRU'\n",
    "      batch_size = 1\n",
    "      hidden_size = hidden\n",
    "      seq_len = 10\n",
    "      epoch_size=10\n",
    "      lr = 0.01\n",
    "      number_of_tasks=4\n",
    "      mask_selection_NofBatch = 50 * 128\n",
    "      input_size=2\n",
    "      many_to_one = True\n",
    "      iteration=iter\n",
    "      mask_init='uniform'\n",
    "      dataset='SINE'\n",
    "      dataset_name = \"sine_rw10_mode5_extended_16-16_1234\"\n",
    "      Pretrain_task = pretrain\n",
    "      ###### End of Config the parameters ######\n",
    "      df = pd.read_csv(os.path.join(f\"datasets/{dataset}/\", f\"{dataset_name}.csv\"))\n",
    "      pretrain_model_addr=f'Performance/Pretrain/{base_model}/{dataset}/After/{dataset}-Task_{Pretrain_task}-{base_model}-pretrain-hidden{hidden_size}-epoch10_iter{iteration}.pickle'\n",
    "      mask_weights=[] #if we have initial masks then reload it here\n",
    "\n",
    "\n",
    "      mask_option = 'SUM'\n",
    "      model_type = 'cPB'\n",
    "      batch_first = True\n",
    "      low_rank = False\n",
    "      first_batch = True\n",
    "      model=cPB(lr = lr ,hidden_size = hidden_size, seq_len = seq_len,base_model = base_model, pretrain_model_addr = pretrain_model_addr,\n",
    "                mask_weights = mask_weights, mask_init = mask_init, number_of_tasks = number_of_tasks, epoch_size = epoch_size,\n",
    "                input_size = input_size, mask_option = mask_option, model_type = model_type, batch_first = batch_first, low_rank = low_rank, many_to_one = many_to_one)\n",
    "\n",
    "\n",
    "      # loop for each task\n",
    "      x_batch = []\n",
    "      y_batch = []\n",
    "      prev_data_x = []\n",
    "      prev_data_y = []\n",
    "      for task in range(1, df[\"task\"].max() + 1):\n",
    "        df_task = df[df[\"task\"] == task]\n",
    "        df_task = df_task.drop(columns=\"task\")\n",
    "        # loop based on each batch of data\n",
    "        batch_cont=0\n",
    "        x = []\n",
    "        y = []\n",
    "        model.weights_copy_anytime(task)\n",
    "        for i in range(0, len(df_task), batch_size):\n",
    "          # x = df_task.iloc[0 : i + batch_size, 0:-1].values.astype(np.float32)\n",
    "          # y = list(df_task.iloc[0 : i + batch_size, -1])\n",
    "          if len(x_batch)==128:\n",
    "            if first_batch==True:\n",
    "              first_batch = False\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            if first_batch == False:\n",
    "              prev_data_x = x[-seq_len:]\n",
    "              prev_data_y = y[-seq_len:]\n",
    "          x_batch.append(df_task.iloc[i, 0:-1].values.astype(np.float32))\n",
    "          y_batch.append(df_task.iloc[i, -1])\n",
    "          \n",
    "          x.append(df_task.iloc[i, 0:-1].values.astype(np.float32))\n",
    "          y.append(df_task.iloc[i, -1])\n",
    "          \n",
    "          # print(len(x))\n",
    "          if len(x) >= seq_len:\n",
    "            if i<mask_selection_NofBatch:\n",
    "              for mask_index in range (0, task):\n",
    "                model.predict_one(x[-seq_len:],y[-seq_len:],mask_index,task,mask_selection=True)\n",
    "                if len(x_batch)==128:\n",
    "                  if first_batch:\n",
    "                    model.learn_many_anytime(x_batch,y_batch,mask_index)\n",
    "                  else:\n",
    "                    new_batch_x = np.concatenate([prev_data_x, x_batch], axis=0) \n",
    "                    new_batch_y = np.concatenate([prev_data_y, y_batch], axis=0)           \n",
    "                    model.learn_many_anytime(new_batch_x,new_batch_y,mask_index)\n",
    "\n",
    "                  \n",
    "              batch_cont+=1\n",
    "            elif i==mask_selection_NofBatch:\n",
    "              best_mask_index=model.add_new_column_anytime(task)\n",
    "              model.predict_one(x[-seq_len:],y[-seq_len:],best_mask_index,task,mask_selection=False)\n",
    "              if len(x_batch)==128:\n",
    "                  new_batch_x = np.concatenate([prev_data_x, x_batch], axis=0) \n",
    "                  new_batch_y = np.concatenate([prev_data_y, y_batch], axis=0)\n",
    "                  model.learn_many_anytime(new_batch_x,new_batch_y,best_mask_index)\n",
    "              batch_cont+=1\n",
    "            elif i>mask_selection_NofBatch:\n",
    "              batch_cont+=1\n",
    "              model.predict_one(x[-seq_len:],y[-seq_len:],best_mask_index,task,mask_selection=False)\n",
    "              if len(x_batch)==128:\n",
    "                  new_batch_x = np.concatenate([prev_data_x, x_batch], axis=0) \n",
    "                  new_batch_y = np.concatenate([prev_data_y, y_batch], axis=0)\n",
    "                  model.learn_many_anytime(new_batch_x,new_batch_y,best_mask_index)\n",
    "        all_y = df_task.iloc[:, -1].reset_index(drop=True)\n",
    "        model.save_final_metrics_anytime(task,all_y)\n",
    "        model.final_weights_saving()\n",
    "\n",
    "\n",
    "      file_path = f'Performance/Results/{model_type}/{dataset}/Anytime/pretrain-T{Pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}_iter{iteration}.pkl'\n",
    "      with open(file_path, 'wb') as file:\n",
    "          pickle.dump(model.performance_anytime, file)\n",
    "\n",
    "      file_path = f'Performance/Results/{model_type}/{dataset}/Anytime/pretrain-T{Pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}_iter{iteration}_selectedMask.pkl'\n",
    "      with open(file_path, 'wb') as file:\n",
    "          pickle.dump(model.selected_mask_index, file)\n",
    "\n",
    "      file_path=f'Performance/Final Models/{model_type}/{base_model}/{dataset}/Anytime/{dataset_name}-{base_model}-pretrain-hidden{hidden_size}-epoch10-Mask_{mask_option}-itter{iteration}.pickle'\n",
    "      with open(file_path, 'wb') as file:\n",
    "          pickle.dump(model.all_models_weight, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3SOVmoXDVKd"
   },
   "source": [
    "# Weather datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size_list = [50]\n",
    "pretrain_mask_list = ['2']\n",
    "for hidden in hidden_size_list:\n",
    "  for pretrain in pretrain_mask_list:\n",
    "    for iter in range(1,11):\n",
    "      ###### Config the parameters ######\n",
    "      base_model = 'GRU'\n",
    "      batch_size = 1\n",
    "      hidden_size = hidden\n",
    "      seq_len = 11\n",
    "      epoch_size=10\n",
    "      lr = 0.01\n",
    "      number_of_tasks=4\n",
    "      mask_selection_NofBatch = 50 * 128\n",
    "      input_size=4\n",
    "      many_to_one = True\n",
    "      iteration=iter\n",
    "      mask_init='uniform'\n",
    "      dataset='Weather'\n",
    "      dataset_name = \"weather_st124_4conf\"\n",
    "      Pretrain_task = '1'\n",
    "      ###### End of Config the parameters ######\n",
    "      df = pd.read_csv(os.path.join(f\"datasets/{dataset}/\", f\"{dataset_name}.csv\"))\n",
    "      pretrain_model_addr=f'Performance/Pretrain/{base_model}/{dataset}/After/{dataset}-{base_model}-pretrain-hidden{hidden_size}-epoch10_itter{iteration}.pickle'\n",
    "      mask_weights=[] #if we have initial masks then reload it here\n",
    "\n",
    "\n",
    "      mask_option = 'SUM'\n",
    "      model_type = 'cPB'\n",
    "      batch_first = True\n",
    "      low_rank = False\n",
    "      first_batch = True\n",
    "      model=cPB(lr = lr ,hidden_size = hidden_size, seq_len = seq_len,base_model = base_model, pretrain_model_addr = pretrain_model_addr,\n",
    "                mask_weights = mask_weights, mask_init = mask_init, number_of_tasks = number_of_tasks, epoch_size = epoch_size,\n",
    "                input_size = input_size, mask_option = mask_option, model_type = model_type, batch_first = batch_first, low_rank = low_rank, many_to_one = many_to_one)\n",
    "\n",
    "\n",
    "      # loop for each task\n",
    "      x_batch = []\n",
    "      y_batch = []\n",
    "      prev_data_x = []\n",
    "      prev_data_y = []\n",
    "      for task in range(1, df[\"task\"].max() + 1):\n",
    "        df_task = df[df[\"task\"] == task]\n",
    "        df_task = df_task.drop(columns=\"task\")\n",
    "        # loop based on each batch of data\n",
    "        batch_cont=0\n",
    "        x = []\n",
    "        y = []\n",
    "        model.weights_copy_anytime(task)\n",
    "        for i in range(0, len(df_task), batch_size):\n",
    "          # x = df_task.iloc[0 : i + batch_size, 0:-1].values.astype(np.float32)\n",
    "          # y = list(df_task.iloc[0 : i + batch_size, -1])\n",
    "          if len(x_batch)==128:\n",
    "            if first_batch==True:\n",
    "              first_batch = False\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            if first_batch == False:\n",
    "              prev_data_x = x[-seq_len:]\n",
    "              prev_data_y = y[-seq_len:]\n",
    "          x_batch.append(df_task.iloc[i, 0:-1].values.astype(np.float32))\n",
    "          y_batch.append(df_task.iloc[i, -1])\n",
    "          \n",
    "          x.append(df_task.iloc[i, 0:-1].values.astype(np.float32))\n",
    "          y.append(df_task.iloc[i, -1])\n",
    "          \n",
    "          # print(len(x))\n",
    "          if len(x) >= seq_len:\n",
    "            if i<mask_selection_NofBatch:\n",
    "              for mask_index in range (0, task):\n",
    "                model.predict_one(x[-seq_len:],y[-seq_len:],mask_index,task,mask_selection=True)\n",
    "                if len(x_batch)==128:\n",
    "                  if first_batch:\n",
    "                    model.learn_many_anytime(x_batch,y_batch,mask_index)\n",
    "                  else:\n",
    "                    new_batch_x = np.concatenate([prev_data_x, x_batch], axis=0) \n",
    "                    new_batch_y = np.concatenate([prev_data_y, y_batch], axis=0)           \n",
    "                    model.learn_many_anytime(new_batch_x,new_batch_y,mask_index)\n",
    "\n",
    "                  \n",
    "              batch_cont+=1\n",
    "            elif i==mask_selection_NofBatch:\n",
    "              best_mask_index=model.add_new_column_anytime(task)\n",
    "              model.predict_one(x[-seq_len:],y[-seq_len:],best_mask_index,task,mask_selection=False)\n",
    "              if len(x_batch)==128:\n",
    "                  new_batch_x = np.concatenate([prev_data_x, x_batch], axis=0) \n",
    "                  new_batch_y = np.concatenate([prev_data_y, y_batch], axis=0)\n",
    "                  model.learn_many_anytime(new_batch_x,new_batch_y,best_mask_index)\n",
    "              batch_cont+=1\n",
    "            elif i>mask_selection_NofBatch:\n",
    "              batch_cont+=1\n",
    "              model.predict_one(x[-seq_len:],y[-seq_len:],best_mask_index,task,mask_selection=False)\n",
    "              if len(x_batch)==128:\n",
    "                  new_batch_x = np.concatenate([prev_data_x, x_batch], axis=0) \n",
    "                  new_batch_y = np.concatenate([prev_data_y, y_batch], axis=0)\n",
    "                  model.learn_many_anytime(new_batch_x,new_batch_y,best_mask_index)\n",
    "        all_y = df_task.iloc[:, -1].reset_index(drop=True)\n",
    "        model.save_final_metrics_anytime(task,all_y)\n",
    "        model.final_weights_saving()\n",
    "      model.plotting()\n",
    "\n",
    "\n",
    "      file_path = f'Performance/Results/{model_type}/{dataset}/Anytime/pretrain-T{Pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}_iter{iteration}.pkl'\n",
    "      with open(file_path, 'wb') as file:\n",
    "          pickle.dump(model.performance_anytime, file)\n",
    "\n",
    "      file_path = f'Performance/Results/{model_type}/{dataset}/Anytime/pretrain-T{Pretrain_task}_{base_model}-{dataset_name}-hidden{hidden_size}-epoch10-Mask_{mask_option}_iter{iteration}_selectedMask.pkl'\n",
    "      with open(file_path, 'wb') as file:\n",
    "          pickle.dump(model.selected_mask_index, file)\n",
    "\n",
    "      file_path=f'Performance/Final Models/{model_type}/{base_model}/{dataset}/Anytime/{dataset_name}-{base_model}-pretrain-hidden{hidden_size}-epoch10-Mask_{mask_option}-itter{iteration}.pickle'\n",
    "      with open(file_path, 'wb') as file:\n",
    "          pickle.dump(model.all_models_weight, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM82h1t6isZ5UsHdGaHl7jp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CPB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
