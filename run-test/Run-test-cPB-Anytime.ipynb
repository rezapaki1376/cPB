{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","os.chdir('..')\n","sys.path.append(os.getcwd())"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","from Models.pretrain import *\n","from Models.cPB_SML import *\n","from Models.cPB import *\n","from river import stream\n","from evaluation.cl_evaluation import EvaluateContinualLearning\n","from evaluation.learner_config import LearnerConfig\n","from evaluation.prequential_evaluation import EvaluatePrequential, make_dir\n","import traceback\n","from evaluation.test_utils import *\n","\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import argparse\n","from torch.autograd import Variable\n","import pprint\n","import copy\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, module='torch.storage')\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch.storage')\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='torch.storage')\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","def create_acpnn_cPB():\n","    global NUM_FEATURES\n","    global SEQ_LEN\n","    global pretrain_model_addr\n","    global hidden_size\n","    global mask_weights\n","    global mask_init\n","    global number_of_tasks\n","    global epoch_size\n","    global lr\n","    global EndOfTask\n","    global many_to_one\n","    return cPB_SML(\n","      lr = lr ,\n","      hidden_size=hidden_size,\n","      seq_len=SEQ_LEN,\n","      pretrain_model_addr=pretrain_model_addr,\n","      mask_weights=mask_weights,\n","      mask_init=mask_init,\n","      number_of_tasks=number_of_tasks,\n","      epoch_size=epoch_size,\n","      input_size=NUM_FEATURES,\n","      EndOftask = EndOfTask,\n","      many_to_one=many_to_one)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dataset_name = 'weather_st124_3conf'\n","dataset = 'Weather'\n","SEQ_LEN = 11 # length of the sequence, 11 for Weather, 10 for Sine\n","ITERATIONS = 1  # number of experiments per each attempt. \n","BATCH_SIZE = 128  # the batch size of periodic learners and classifiers.\n","base_model = 'GRU'\n","NUM_FEATURES = 4\n","NUM_CLASSES = 2\n","NUM_OLD_LABELS = SEQ_LEN - 1\n","MAX_SAMPLES = None\n","TRAIN_TEST = False\n","WRITE_CHECKPOINTS = False\n","DO_CL = False\n","ANYTIME_SCENARIO = True\n","PERIODIC_SCENARIO = True\n","hidden_size = 250\n","mask_weights = []\n","epoch_size=10\n","lr = 0.01\n","number_of_tasks=4\n","mask_selection_NofBatch = 50\n","mask_init='uniform'\n","pretrain_model_addr =''\n","many_to_one=True\n","\n","\n","METRICS = [\"accuracy\", \"kappa\"]\n","PATHS = [\n","    f\"datasets/Weather/{dataset_name}\",\n","]  # a list containing the paths of the data streams (without the extension)\n","data = pd.read_csv(f\"{PATHS[0]}.csv\")\n","EndOfTask = len(data[data['task']==1])/128\n","\n","PATH_PERFORMANCE = \"logs\"  # path to write the outputs of the evaluation\n","CALLBACK_FUNC = None  # function to call after each iteration (set it to None)\n","MODE = \"local\"  # 'local' or 'aws'. If 'aws', the messages will be written in a specific txt file in the output_file dir\n","OUTPUT_FILE = None\n","# the name of the output file in outputs dir. If None, it will use the name of the current data stream.\n","suffix = f\"\"  # the suffix to add the files containing the evaluation results."]},{"cell_type":"markdown","metadata":{"id":"Q3SOVmoXDVKd"},"source":["# Weather datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","for iter in range(1,11):\n","    pretrain_model_addr=f'Performance/Pretrain/{base_model}/{dataset}/After/weather-{base_model}-pretrain-hidden{hidden_size}-epoch10_itter{counter}.pickle'\n","\n","    anytime_learners_sml = []\n","    batch_learners = [\n","        LearnerConfig(\n","            name=\"cGRU\",\n","            model=create_acpnn_cPB,\n","            numeric=True,\n","            batch_learner=True,\n","            drift=True,\n","            cpnn=True,\n","        )]\n","\n","\n","    anytime_learners = anytime_learners_sml\n","\n","    # The list of LearnerConfig specifying the anytime learners.\n","    # The associated models are able to perform training and inference on single data points.\n","    # They must implement the methods learn_one(x, y), predict_one(x).\n","    # Use anytime_learners_sml to add all the SML models. Use [] if you are not interested in testing anytime learners.\n","    # Otherwise, specify a custom list of LearnerConfig.\n","    batch_learners = batch_learners\n","    # The list of LearnerConfig specifying the periodic learners.\n","    # The associated models are able to perform training only on mini-batches of data points.\n","    # They must implement the methods learn_many(x, y), predict_many(x), predict_one(x).\n","    # Use batch_learners_acpnn_qcpnn for the experiment on acpnn and qcpnn.\n","    # Use batch_learners_fcpnn to run the single model for fcpnn experiment.\n","    # Otherwise, specify a custom list of LearnerConfig.\n","\n","\n","    # __________________\n","    # CODE\n","    # __________________\n","\n","\n","    if OUTPUT_FILE is None:\n","        OUTPUT_FILE = PATHS[0].split(\"/\")[-1]\n","\n","    initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","    eval_cl = None\n","\n","\n","    def create_iter_csv():\n","        return stream.iter_csv(str(PATH) + \".csv\", converters=converters, target=\"target\")\n","\n","\n","    PATH = \"\"\n","    if not PATH_PERFORMANCE.startswith(\"/\"):\n","        PATH_PERFORMANCE = os.path.join(\"performance\", PATH_PERFORMANCE)\n","\n","    orig_stdout = sys.stdout\n","    f = None\n","    if MODE == \"aws\":\n","        make_dir(f\"outputs\")\n","        f = open(f\"outputs/{OUTPUT_FILE}.txt\", \"w\", buffering=1)\n","        sys.stdout = f\n","\n","    try:\n","        for path in PATHS:\n","            PATH = path\n","            current_path_performance = os.path.join(PATH_PERFORMANCE, PATH.split(\"/\")[-1])\n","            make_dir(current_path_performance)\n","\n","            if TRAIN_TEST:\n","                PATH_CL = PATH + \"_test\"\n","                PATH = PATH + \"_train\"\n","            else:\n","                PATH_CL = PATH\n","            df = pd.read_csv(f\"{PATH}.csv\", nrows=1)\n","            columns = list(df.columns)\n","            initial_task = df.iloc[0][\"task\"]\n","            columns.remove(\"target\")\n","            columns.remove(\"task\")\n","            converters = {c: float for c in columns}\n","            converters[\"target\"] = int\n","            converters[\"task\"] = int\n","            NUM_FEATURES = len(columns)\n","            data_stream = create_iter_csv\n","\n","            initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","            print(PATH)\n","            print(\"BATCH SIZE, SEQ LEN:\", BATCH_SIZE, SEQ_LEN)\n","            print(\"NUM OLD LABELS:\", NUM_OLD_LABELS)\n","            print(\"TRAIN TEST:\", TRAIN_TEST)\n","            print(\"ANYTIME LEARNERS:\", [m.name for m in anytime_learners])\n","            print(\"BATCH LEARNERS:\", [(m.name, m.drift) for m in batch_learners])\n","            print(\"SUFFIX:\", suffix)\n","            print()\n","\n","            eval_preq = EvaluatePrequential(\n","                max_data_points=MAX_SAMPLES,\n","                batch_size=BATCH_SIZE,\n","                metrics=METRICS,\n","                anytime_learners=anytime_learners,\n","                batch_learners=batch_learners,\n","                data_stream=data_stream,\n","                path_write=current_path_performance,\n","                train_test=TRAIN_TEST,\n","                suffix=suffix,\n","                write_checkpoints=WRITE_CHECKPOINTS,\n","                iterations=ITERATIONS,\n","                dataset_name=PATH.split(\"/\")[-1],\n","                mode=MODE,\n","                anytime_scenario=ANYTIME_SCENARIO,\n","                periodic_scenario=PERIODIC_SCENARIO,\n","            )\n","\n","            if PATH_CL is not None and DO_CL:\n","                eval_cl = EvaluateContinualLearning(\n","                    path=PATH_CL,\n","                    checkpoint=eval_preq.checkpoint,\n","                    anytime_learners=anytime_learners,\n","                    batch_learners=batch_learners,\n","                    batch_size=BATCH_SIZE,\n","                    path_write=current_path_performance,\n","                    train_test=TRAIN_TEST,\n","                    suffix=suffix,\n","                )\n","\n","            initialize_callback(eval_cl, eval_preq)\n","\n","            eval_preq.evaluate(callback=CALLBACK_FUNC, initial_task=initial_task)\n","            print()\n","    except Exception:\n","        print(traceback.format_exc())\n","        if MODE == \"aws\":\n","            sys.stdout = orig_stdout\n","            f.close()\n","            print(traceback.format_exc())\n","    print(\"\\n\\nEND.\")\n","    if MODE == \"aws\":\n","        sys.stdout = orig_stdout\n","        f.close()\n","    file_path = f'Performance/Results/cPB/{dataset}/Anytime/{dataset_name}-hidden{hidden_size}-epoch10_itter{iter}.pkl'\n","    # Open the file in binary write mode\n","    with open(file_path, 'wb') as file:\n","        # Dump the dictionary into the file using pickle\n","        pickle.dump(eval_preq._eval['cGRU_anytime']['alg'][0].performance, file)\n","\n","\n","    file_path = f'Performance/Results/cPB/{dataset}/Anytime/{dataset_name}-hidden{hidden_size}-epoch10_itter{iter}_selectedMask.pkl'\n","\n","    # Open the file in binary write mode\n","    with open(file_path, 'wb') as file:\n","        # Dump the dictionary into the file using pickle\n","        pickle.dump(eval_preq._eval['cGRU_anytime']['alg'][0].selected_model_index, file)\n","    print(f'Itter {counter} finished................')\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# SINE datasets\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["dataset_name = \"sine_rw10_mode5_extended_16-16_1234\"\n","dataset = 'SINE'\n","SEQ_LEN = 10 # length of the sequence, 11 for Weather, 10 for Sine\n","ITERATIONS = 1  # number of experiments per each attempt. \n","BATCH_SIZE = 128  # the batch size of periodic learners and classifiers.\n","base_model = 'GRU'\n","NUM_FEATURES = 2\n","NUM_CLASSES = 2\n","NUM_OLD_LABELS = SEQ_LEN - 1\n","MAX_SAMPLES = None\n","TRAIN_TEST = False\n","WRITE_CHECKPOINTS = False\n","DO_CL = False\n","ANYTIME_SCENARIO = True\n","PERIODIC_SCENARIO = True\n","hidden_size = 250\n","mask_weights = []\n","epoch_size=10\n","lr = 0.01\n","number_of_tasks=4\n","mask_selection_NofBatch = 50\n","mask_init='uniform'\n","pretrain_model_addr =''\n","many_to_one=True\n","Pretrain_task= '1'\n","\n","\n","METRICS = [\"accuracy\", \"kappa\"]\n","PATHS = [\n","    f\"datasets/SINE/{dataset_name}\",\n","]  # a list containing the paths of the data streams (without the extension)\n","data = pd.read_csv(f\"{PATHS[0]}.csv\")\n","EndOfTask = len(data[data['task']==1])/128\n","\n","PATH_PERFORMANCE = \"logs\"  # path to write the outputs of the evaluation\n","CALLBACK_FUNC = None  # function to call after each iteration (set it to None)\n","MODE = \"local\"  # 'local' or 'aws'. If 'aws', the messages will be written in a specific txt file in the output_file dir\n","OUTPUT_FILE = None\n","# the name of the output file in outputs dir. If None, it will use the name of the current data stream.\n","suffix = f\"\"  # the suffix to add the files containing the evaluation results.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","for iter in range(1,11):\n","    pretrain_model_addr=f'Performance/Pretrain/GRU/{dataset}/After/sine-6_6-1234-t{Pretrain_task}-{base_model}-pretrain-hidden{hidden_size}-epoch10_itter{iter}.pickle'\n","\n","    anytime_learners_sml = []\n","    batch_learners = [\n","        LearnerConfig(\n","            name=\"cGRU\",\n","            model=create_acpnn_cPB,\n","            numeric=True,\n","            batch_learner=True,\n","            drift=True,\n","            cpnn=True,\n","        )]\n","\n","\n","    anytime_learners = anytime_learners_sml\n","\n","    # The list of LearnerConfig specifying the anytime learners.\n","    # The associated models are able to perform training and inference on single data points.\n","    # They must implement the methods learn_one(x, y), predict_one(x).\n","    # Use anytime_learners_sml to add all the SML models. Use [] if you are not interested in testing anytime learners.\n","    # Otherwise, specify a custom list of LearnerConfig.\n","    batch_learners = batch_learners\n","    # The list of LearnerConfig specifying the periodic learners.\n","    # The associated models are able to perform training only on mini-batches of data points.\n","    # They must implement the methods learn_many(x, y), predict_many(x), predict_one(x).\n","    # Use batch_learners_acpnn_qcpnn for the experiment on acpnn and qcpnn.\n","    # Use batch_learners_fcpnn to run the single model for fcpnn experiment.\n","    # Otherwise, specify a custom list of LearnerConfig.\n","\n","\n","    # __________________\n","    # CODE\n","    # __________________\n","\n","\n","    if OUTPUT_FILE is None:\n","        OUTPUT_FILE = PATHS[0].split(\"/\")[-1]\n","\n","    initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","    eval_cl = None\n","\n","\n","    def create_iter_csv():\n","        return stream.iter_csv(str(PATH) + \".csv\", converters=converters, target=\"target\")\n","\n","\n","    PATH = \"\"\n","    if not PATH_PERFORMANCE.startswith(\"/\"):\n","        PATH_PERFORMANCE = os.path.join(\"performance\", PATH_PERFORMANCE)\n","\n","    orig_stdout = sys.stdout\n","    f = None\n","    if MODE == \"aws\":\n","        make_dir(f\"outputs\")\n","        f = open(f\"outputs/{OUTPUT_FILE}.txt\", \"w\", buffering=1)\n","        sys.stdout = f\n","\n","    try:\n","        for path in PATHS:\n","            PATH = path\n","            current_path_performance = os.path.join(PATH_PERFORMANCE, PATH.split(\"/\")[-1])\n","            make_dir(current_path_performance)\n","\n","            if TRAIN_TEST:\n","                PATH_CL = PATH + \"_test\"\n","                PATH = PATH + \"_train\"\n","            else:\n","                PATH_CL = PATH\n","            df = pd.read_csv(f\"{PATH}.csv\", nrows=1)\n","            columns = list(df.columns)\n","            initial_task = df.iloc[0][\"task\"]\n","            columns.remove(\"target\")\n","            columns.remove(\"task\")\n","            converters = {c: float for c in columns}\n","            converters[\"target\"] = int\n","            converters[\"task\"] = int\n","            NUM_FEATURES = len(columns)\n","            data_stream = create_iter_csv\n","\n","            initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","            print(PATH)\n","            print(\"BATCH SIZE, SEQ LEN:\", BATCH_SIZE, SEQ_LEN)\n","            print(\"NUM OLD LABELS:\", NUM_OLD_LABELS)\n","            print(\"TRAIN TEST:\", TRAIN_TEST)\n","            print(\"ANYTIME LEARNERS:\", [m.name for m in anytime_learners])\n","            print(\"BATCH LEARNERS:\", [(m.name, m.drift) for m in batch_learners])\n","            print(\"SUFFIX:\", suffix)\n","            print()\n","\n","            eval_preq = EvaluatePrequential(\n","                max_data_points=MAX_SAMPLES,\n","                batch_size=BATCH_SIZE,\n","                metrics=METRICS,\n","                anytime_learners=anytime_learners,\n","                batch_learners=batch_learners,\n","                data_stream=data_stream,\n","                path_write=current_path_performance,\n","                train_test=TRAIN_TEST,\n","                suffix=suffix,\n","                write_checkpoints=WRITE_CHECKPOINTS,\n","                iterations=ITERATIONS,\n","                dataset_name=PATH.split(\"/\")[-1],\n","                mode=MODE,\n","                anytime_scenario=ANYTIME_SCENARIO,\n","                periodic_scenario=PERIODIC_SCENARIO,\n","            )\n","\n","            if PATH_CL is not None and DO_CL:\n","                eval_cl = EvaluateContinualLearning(\n","                    path=PATH_CL,\n","                    checkpoint=eval_preq.checkpoint,\n","                    anytime_learners=anytime_learners,\n","                    batch_learners=batch_learners,\n","                    batch_size=BATCH_SIZE,\n","                    path_write=current_path_performance,\n","                    train_test=TRAIN_TEST,\n","                    suffix=suffix,\n","                )\n","\n","            initialize_callback(eval_cl, eval_preq)\n","\n","            eval_preq.evaluate(callback=CALLBACK_FUNC, initial_task=initial_task)\n","            print()\n","    except Exception:\n","        print(traceback.format_exc())\n","        if MODE == \"aws\":\n","            sys.stdout = orig_stdout\n","            f.close()\n","            print(traceback.format_exc())\n","    print(\"\\n\\nEND.\")\n","    if MODE == \"aws\":\n","        sys.stdout = orig_stdout\n","        f.close()\n","    file_path = f'Performance/Results/cPB/{dataset}/Anytime/{dataset_name}-hidden{hidden_size}-epoch10_itter{iter}.pkl'\n","    # Open the file in binary write mode\n","    with open(file_path, 'wb') as file:\n","        # Dump the dictionary into the file using pickle\n","        pickle.dump(eval_preq._eval['cGRU_anytime']['alg'][0].performance, file)\n","\n","\n","    file_path = f'Performance/Results/cPB/{dataset}/Anytime/{dataset_name}-hidden{hidden_size}-epoch10_itter{iter}_selectedMask.pkl'\n","\n","    # Open the file in binary write mode\n","    with open(file_path, 'wb') as file:\n","        # Dump the dictionary into the file using pickle\n","        pickle.dump(eval_preq._eval['cGRU_anytime']['alg'][0].selected_model_index, file)\n","    print(f'Itter {counter} finished................')\n","\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM82h1t6isZ5UsHdGaHl7jp","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}
