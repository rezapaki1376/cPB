{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","os.chdir('..')\n","sys.path.append(os.getcwd())"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","from Models.pretrain import *\n","from Models.cPB_SML import *\n","from Models.cPB import *\n","from river import stream\n","from evaluation.cl_evaluation import EvaluateContinualLearning\n","from evaluation.learner_config import LearnerConfig\n","from evaluation.prequential_evaluation import EvaluatePrequential, make_dir\n","import traceback\n","from evaluation.test_utils import *\n","\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import argparse\n","from torch.autograd import Variable\n","import pprint\n","import copy\n","import warnings\n","from Models.cgru import cGRULinear\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, module='torch.storage')\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch.storage')\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='torch.storage')\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class ModelLoader:\n","  def __init__(self,base_model,dataset):\n","      self.iteration = 1\n","      self.path = None\n","      self.base_model = base_model\n","      self.dataset = dataset\n","\n","  def return_base_learner_pretrained(self):\n","\n","      with open(f\"pretrain/GRU/weather/before/{self.path + self.iteration}.pickle\", \"rb\") as f:\n","          model = pickle.load(f)\n","      return model\n","\n","  def return_base_learner(self,input_size,output_size,hidden_size,batch_size,device,many_to_one):\n","      with open(f\"performance/pretrain/{self.base_model}/{self.dataset}/before/{self.path + str(self.iteration)}.pickle\", \"rb\") as f:\n","          pretrained_model = pickle.load(f)\n","      model = cGRULinear(\n","            input_size=input_size,\n","            output_size=output_size,\n","            hidden_size=hidden_size,\n","            batch_size=batch_size,\n","            device=device,\n","            many_to_one=many_to_one\n","        )\n","\n","        # Load the weights from the pretrained model into the cGRULinear instance\n","      model.load_state_dict(pretrained_model)\n","      self.iteration += 1\n","\n","\n","      return model\n","\n","  def next_iteration(self):\n","      self.iteration += 1\n","\n","  def set_path(self, path):\n","      self.path = path"]},{"cell_type":"markdown","metadata":{"id":"Q3SOVmoXDVKd"},"source":["# Weather datasets\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dataset_name = 'weather_st124_3conf'\n","dataset = 'Weather'\n","SEQ_LEN = 11 # length of the sequence, 11 for Weather, 10 for Sine\n","ITERATIONS = 1  # number of experiments per each attempt. \n","BATCH_SIZE = 128  # the batch size of periodic learners and classifiers.\n","base_model = 'GRU'\n","NUM_FEATURES = 4\n","NUM_CLASSES = 2\n","NUM_OLD_LABELS = SEQ_LEN - 1\n","MAX_SAMPLES = None\n","TRAIN_TEST = False\n","WRITE_CHECKPOINTS = False\n","DO_CL = False\n","ANYTIME_SCENARIO = True\n","PERIODIC_SCENARIO = True\n","hidden_size = 250\n","mask_weights = []\n","epoch_size=10\n","lr = 0.01\n","number_of_tasks=4\n","mask_selection_NofBatch = 50\n","mask_init='uniform'\n","pretrain_model_addr =''\n","many_to_one=True\n","pretrain_model_path = f'weather-{base_model}-pretrain-hidden{hidden_size}-epoch10_itter'\n","\n","METRICS = [\"accuracy\", \"kappa\"]\n","PATHS = [\n","    f\"datasets/Weather/{dataset_name}\",\n","]  # a list containing the paths of the data streams (without the extension)\n","\n","\n","PATH_PERFORMANCE = f\"Results/cGRU/hidden{hidden_size}\"  # path to write the outputs of the evaluation\n","CALLBACK_FUNC = None  # function to call after each iteration (set it to None)\n","MODE = \"local\"  # 'local' or 'aws'. If 'aws', the messages will be written in a specific txt file in the output_file dir\n","OUTPUT_FILE = None\n","# the name of the output file in outputs dir. If None, it will use the name of the current data stream.\n","suffix = f\"\"  # the suffix to add the files containing the evaluation results."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["datasets/Weather/weather_st124_3conf\n","BATCH SIZE, SEQ LEN: 128 11\n","NUM OLD LABELS: 10\n","TRAIN TEST: False\n","ANYTIME LEARNERS: []\n","BATCH LEARNERS: [('cGRU', False)]\n","SUFFIX: \n","\n","weather_st124_3conf 1/1 24100\n","DETECTED DRIFT: 24105\n","weather_st124_3conf 1/1 48200\n","DETECTED DRIFT: 48210\n","weather_st124_3conf 1/1 72300\n","DETECTED DRIFT: 72315\n","weather_st124_3conf 1/1 96400\n","\n","\n","\n","\n","END.\n"]}],"source":["\n","\n","\n","MODEL_LOADER = ModelLoader(dataset=dataset,base_model=base_model)\n","\n","def create_acpnn_cgru():\n","  return cPNN(\n","      column_class=MODEL_LOADER.return_base_learner,\n","      device=\"cpu\",\n","      seq_len=SEQ_LEN,\n","      train_verbose=False,\n","      acpnn=True,\n","      batch_size=BATCH_SIZE,\n","      input_size=NUM_FEATURES,\n","      output_size=2,\n","      hidden_size=250)\n","\n","batch_learners = [\n","    LearnerConfig(\n","         name=\"cGRU\",\n","         model=create_acpnn_cgru,\n","         numeric=True,\n","         batch_learner=True,\n","         drift=False,\n","         cpnn=True,\n","     )\n","    ]\n","\n","\n","anytime_learners = []\n","\n","# The list of LearnerConfig specifying the anytime learners.\n","# The associated models are able to perform training and inference on single data points.\n","# They must implement the methods learn_one(x, y), predict_one(x).\n","# Use anytime_learners_sml to add all the SML models. Use [] if you are not interested in testing anytime learners.\n","# Otherwise, specify a custom list of LearnerConfig.\n","batch_learners = batch_learners\n","# The list of LearnerConfig specifying the periodic learners.\n","# The associated models are able to perform training only on mini-batches of data points.\n","# They must implement the methods learn_many(x, y), predict_many(x), predict_one(x).\n","# Use batch_learners_acpnn_qcpnn for the experiment on acpnn and qcpnn.\n","# Use batch_learners_fcpnn to run the single model for fcpnn experiment.\n","# Otherwise, specify a custom list of LearnerConfig.\n","\n","\n","# __________________\n","# CODE\n","# __________________\n","\n","if OUTPUT_FILE is None:\n","    OUTPUT_FILE = PATHS[0].split(\"/\")[-1]\n","\n","initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","eval_cl = None\n","\n","\n","def create_iter_csv():\n","    return stream.iter_csv(str(PATH) + \".csv\", converters=converters, target=\"target\")\n","\n","def next_iteration_callback(**kwargs):\n","    MODEL_LOADER.next_iteration()\n","\n","\n","CALLBACK_FUNC = next_iteration_callback\n","\n","\n","PATH = \"\"\n","if not PATH_PERFORMANCE.startswith(\"/\"):\n","    PATH_PERFORMANCE = os.path.join(\"performance\", PATH_PERFORMANCE)\n","\n","orig_stdout = sys.stdout\n","f = None\n","if MODE == \"aws\":\n","    make_dir(f\"outputs\")\n","    f = open(f\"outputs/{OUTPUT_FILE}.txt\", \"w\", buffering=1)\n","    sys.stdout = f\n","\n","try:\n","    for path in PATHS:\n","        PATH = path\n","        MODEL_LOADER.set_path(pretrain_model_path)\n","        current_path_performance = os.path.join(PATH_PERFORMANCE, PATH.split(\"/\")[-1])\n","        make_dir(current_path_performance)\n","\n","        if TRAIN_TEST:\n","            PATH_CL = PATH + \"_test\"\n","            PATH = PATH + \"_train\"\n","        else:\n","            PATH_CL = PATH\n","        df = pd.read_csv(f\"{PATH}.csv\", nrows=1)\n","        columns = list(df.columns)\n","        initial_task = df.iloc[0][\"task\"]\n","        columns.remove(\"target\")\n","        columns.remove(\"task\")\n","        converters = {c: float for c in columns}\n","        converters[\"target\"] = int\n","        converters[\"task\"] = int\n","        NUM_FEATURES = len(columns)\n","        data_stream = create_iter_csv\n","\n","        initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","        print(PATH)\n","        print(\"BATCH SIZE, SEQ LEN:\", BATCH_SIZE, SEQ_LEN)\n","        print(\"NUM OLD LABELS:\", NUM_OLD_LABELS)\n","        print(\"TRAIN TEST:\", TRAIN_TEST)\n","        print(\"ANYTIME LEARNERS:\", [m.name for m in anytime_learners])\n","        print(\"BATCH LEARNERS:\", [(m.name, m.drift) for m in batch_learners])\n","        print(\"SUFFIX:\", suffix)\n","        print()\n","\n","        eval_preq = EvaluatePrequential(\n","            max_data_points=MAX_SAMPLES,\n","            batch_size=BATCH_SIZE,\n","            metrics=METRICS,\n","            anytime_learners=anytime_learners,\n","            batch_learners=batch_learners,\n","            data_stream=data_stream,\n","            path_write=current_path_performance,\n","            train_test=TRAIN_TEST,\n","            suffix=suffix,\n","            write_checkpoints=WRITE_CHECKPOINTS,\n","            iterations=ITERATIONS,\n","            dataset_name=PATH.split(\"/\")[-1],\n","            mode=MODE,\n","            anytime_scenario=ANYTIME_SCENARIO,\n","            periodic_scenario=PERIODIC_SCENARIO,\n","        )\n","\n","        if PATH_CL is not None and DO_CL:\n","            eval_cl = EvaluateContinualLearning(\n","                path=PATH_CL,\n","                checkpoint=eval_preq.checkpoint,\n","                anytime_learners=anytime_learners,\n","                batch_learners=batch_learners,\n","                batch_size=BATCH_SIZE,\n","                path_write=current_path_performance,\n","                train_test=TRAIN_TEST,\n","                suffix=suffix,\n","            )\n","\n","        initialize_callback(eval_cl, eval_preq)\n","\n","        eval_preq.evaluate(callback=CALLBACK_FUNC, initial_task=initial_task)\n","        print()\n","except Exception:\n","    print(traceback.format_exc())\n","    if MODE == \"aws\":\n","        sys.stdout = orig_stdout\n","        f.close()\n","        print(traceback.format_exc())\n","print(\"\\n\\nEND.\")\n","if MODE == \"aws\":\n","    sys.stdout = orig_stdout\n","    f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# SINE datasets\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["dataset_name = \"sine_rw10_mode5_extended_16-16_1234\"\n","dataset = 'SINE'\n","SEQ_LEN = 10 # length of the sequence, 11 for Weather, 10 for Sine\n","ITERATIONS = 1  # number of experiments per each attempt. \n","BATCH_SIZE = 128  # the batch size of periodic learners and classifiers.\n","base_model = 'GRU'\n","NUM_FEATURES = 2\n","NUM_CLASSES = 2\n","NUM_OLD_LABELS = SEQ_LEN - 1\n","MAX_SAMPLES = None\n","TRAIN_TEST = False\n","WRITE_CHECKPOINTS = False\n","DO_CL = False\n","ANYTIME_SCENARIO = True\n","PERIODIC_SCENARIO = True\n","hidden_size = 250\n","mask_weights = []\n","epoch_size=10\n","lr = 0.01\n","number_of_tasks=4\n","mask_selection_NofBatch = 50\n","mask_init='uniform'\n","pretrain_model_addr =''\n","many_to_one=True\n","Pretrain_task= '1'\n","\n","\n","METRICS = [\"accuracy\", \"kappa\"]\n","PATHS = [\n","    f\"datasets/SINE/{dataset_name}\",\n","]  # a list containing the paths of the data streams (without the extension)\n","\n","pretrain_model_path = f'sine-6_6-1234-t{Pretrain_task}-{base_model}-pretrain-hidden{hidden_size}-epoch10_itter'\n","\n","PATH_PERFORMANCE = f\"Results/cGRU/hidden{hidden_size}\"  # path to write the outputs of the evaluation\n","CALLBACK_FUNC = None  # function to call after each iteration (set it to None)\n","MODE = \"local\"  # 'local' or 'aws'. If 'aws', the messages will be written in a specific txt file in the output_file dir\n","OUTPUT_FILE = None\n","# the name of the output file in outputs dir. If None, it will use the name of the current data stream.\n","suffix = f\"\"  # the suffix to add the files containing the evaluation results.\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["datasets/SINE/sine_rw10_mode5_extended_16-16_1234\n","BATCH SIZE, SEQ LEN: 128 10\n","NUM OLD LABELS: 9\n","TRAIN TEST: False\n","ANYTIME LEARNERS: []\n","BATCH LEARNERS: [('cGRU', False)]\n","SUFFIX: \n","\n","sine_rw10_mode5_extended_16-16_1234 1/1 50000\n","DETECTED DRIFT: 50000\n","sine_rw10_mode5_extended_16-16_1234 1/1 100000\n","DETECTED DRIFT: 100000\n","sine_rw10_mode5_extended_16-16_1234 1/1 150000\n","DETECTED DRIFT: 150000\n","sine_rw10_mode5_extended_16-16_1234 1/1 200000\n","\n","\n","\n","\n","END.\n"]}],"source":["\n","\n","\n","MODEL_LOADER = ModelLoader(dataset=dataset,base_model=base_model)\n","\n","def create_acpnn_cgru():\n","  return cPNN(\n","      column_class=MODEL_LOADER.return_base_learner,\n","      device=\"cpu\",\n","      seq_len=SEQ_LEN,\n","      train_verbose=False,\n","      acpnn=True,\n","      batch_size=BATCH_SIZE,\n","      input_size=NUM_FEATURES,\n","      output_size=2,\n","      hidden_size=250)\n","\n","batch_learners = [\n","    LearnerConfig(\n","         name=\"cGRU\",\n","         model=create_acpnn_cgru,\n","         numeric=True,\n","         batch_learner=True,\n","         drift=False,\n","         cpnn=True,\n","     )\n","    ]\n","\n","\n","anytime_learners = []\n","\n","# The list of LearnerConfig specifying the anytime learners.\n","# The associated models are able to perform training and inference on single data points.\n","# They must implement the methods learn_one(x, y), predict_one(x).\n","# Use anytime_learners_sml to add all the SML models. Use [] if you are not interested in testing anytime learners.\n","# Otherwise, specify a custom list of LearnerConfig.\n","batch_learners = batch_learners\n","# The list of LearnerConfig specifying the periodic learners.\n","# The associated models are able to perform training only on mini-batches of data points.\n","# They must implement the methods learn_many(x, y), predict_many(x), predict_one(x).\n","# Use batch_learners_acpnn_qcpnn for the experiment on acpnn and qcpnn.\n","# Use batch_learners_fcpnn to run the single model for fcpnn experiment.\n","# Otherwise, specify a custom list of LearnerConfig.\n","\n","\n","# __________________\n","# CODE\n","# __________________\n","\n","if OUTPUT_FILE is None:\n","    OUTPUT_FILE = PATHS[0].split(\"/\")[-1]\n","\n","initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","eval_cl = None\n","\n","\n","def create_iter_csv():\n","    return stream.iter_csv(str(PATH) + \".csv\", converters=converters, target=\"target\")\n","\n","def next_iteration_callback(**kwargs):\n","    MODEL_LOADER.next_iteration()\n","\n","\n","CALLBACK_FUNC = next_iteration_callback\n","\n","\n","PATH = \"\"\n","if not PATH_PERFORMANCE.startswith(\"/\"):\n","    PATH_PERFORMANCE = os.path.join(\"performance\", PATH_PERFORMANCE)\n","\n","orig_stdout = sys.stdout\n","f = None\n","if MODE == \"aws\":\n","    make_dir(f\"outputs\")\n","    f = open(f\"outputs/{OUTPUT_FILE}.txt\", \"w\", buffering=1)\n","    sys.stdout = f\n","\n","try:\n","    for path in PATHS:\n","        PATH = path\n","        MODEL_LOADER.set_path(pretrain_model_path)\n","        current_path_performance = os.path.join(PATH_PERFORMANCE, PATH.split(\"/\")[-1])\n","        make_dir(current_path_performance)\n","\n","        if TRAIN_TEST:\n","            PATH_CL = PATH + \"_test\"\n","            PATH = PATH + \"_train\"\n","        else:\n","            PATH_CL = PATH\n","        df = pd.read_csv(f\"{PATH}.csv\", nrows=1)\n","        columns = list(df.columns)\n","        initial_task = df.iloc[0][\"task\"]\n","        columns.remove(\"target\")\n","        columns.remove(\"task\")\n","        converters = {c: float for c in columns}\n","        converters[\"target\"] = int\n","        converters[\"task\"] = int\n","        NUM_FEATURES = len(columns)\n","        data_stream = create_iter_csv\n","\n","        initialize(NUM_OLD_LABELS, SEQ_LEN, NUM_FEATURES, BATCH_SIZE, ITERATIONS)\n","        print(PATH)\n","        print(\"BATCH SIZE, SEQ LEN:\", BATCH_SIZE, SEQ_LEN)\n","        print(\"NUM OLD LABELS:\", NUM_OLD_LABELS)\n","        print(\"TRAIN TEST:\", TRAIN_TEST)\n","        print(\"ANYTIME LEARNERS:\", [m.name for m in anytime_learners])\n","        print(\"BATCH LEARNERS:\", [(m.name, m.drift) for m in batch_learners])\n","        print(\"SUFFIX:\", suffix)\n","        print()\n","\n","        eval_preq = EvaluatePrequential(\n","            max_data_points=MAX_SAMPLES,\n","            batch_size=BATCH_SIZE,\n","            metrics=METRICS,\n","            anytime_learners=anytime_learners,\n","            batch_learners=batch_learners,\n","            data_stream=data_stream,\n","            path_write=current_path_performance,\n","            train_test=TRAIN_TEST,\n","            suffix=suffix,\n","            write_checkpoints=WRITE_CHECKPOINTS,\n","            iterations=ITERATIONS,\n","            dataset_name=PATH.split(\"/\")[-1],\n","            mode=MODE,\n","            anytime_scenario=ANYTIME_SCENARIO,\n","            periodic_scenario=PERIODIC_SCENARIO,\n","        )\n","\n","        if PATH_CL is not None and DO_CL:\n","            eval_cl = EvaluateContinualLearning(\n","                path=PATH_CL,\n","                checkpoint=eval_preq.checkpoint,\n","                anytime_learners=anytime_learners,\n","                batch_learners=batch_learners,\n","                batch_size=BATCH_SIZE,\n","                path_write=current_path_performance,\n","                train_test=TRAIN_TEST,\n","                suffix=suffix,\n","            )\n","\n","        initialize_callback(eval_cl, eval_preq)\n","\n","        eval_preq.evaluate(callback=CALLBACK_FUNC, initial_task=initial_task)\n","        print()\n","except Exception:\n","    print(traceback.format_exc())\n","    if MODE == \"aws\":\n","        sys.stdout = orig_stdout\n","        f.close()\n","        print(traceback.format_exc())\n","print(\"\\n\\nEND.\")\n","if MODE == \"aws\":\n","    sys.stdout = orig_stdout\n","    f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM82h1t6isZ5UsHdGaHl7jp","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}
